{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building RAG Chatbots with LangChain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we'll work on building an AI chatbot from start-to-finish. We will be using LangChain, OpenAI, and Pinecone vector DB, to build a chatbot capable of learning from the external world using **R**etrieval **A**ugmented **G**eneration (RAG).\n",
    "\n",
    "We will be using a dataset sourced from the Llama 2 ArXiv paper and other related papers to help our chatbot answer questions about the latest and greatest in the world of GenAI.\n",
    "\n",
    "By the end of the example we'll have a functioning chatbot and RAG pipeline that can hold a conversation and provide informative responses based on a knowledge base.\n",
    "\n",
    "### Before you begin\n",
    "\n",
    "You'll need to get an [OpenAI API key](https://platform.openai.com/account/api-keys) and [Pinecone API key](https://app.pinecone.io). If you have completed previous assignments and followed along in class, you will have these already stored in a .env file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "import os\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "PINECONE_ENVIRONMENT = os.getenv(\"PINECONE_ENVIRONMENT\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start building our chatbot, we need to install some Python libraries. Here's a brief overview of what each library does:\n",
    "\n",
    "- **langchain**: This is a [library for Generative AI](https://python.langchain.com/docs/get_started/introduction). We'll use it to chain together different language models and components for our chatbot.\n",
    "- **openai**: This is the official [OpenAI Python client](https://github.com/openai/openai-python). We'll use it to interact with the OpenAI API and generate responses for our chatbot.\n",
    "- **datasets**: This library provides a [vast array of datasets](https://pypi.org/project/datasets/) for machine learning. We'll use it to load our knowledge base for the chatbot.\n",
    "- **pinecone-client**: This is the official Pinecone Python client. We'll use it to interact with the Pinecone API and store our chatbot's knowledge base in a vector database.\n",
    "- **tiktoken**: [tiktoken](https://github.com/openai/tiktoken) is a fast BPE ([Byte Pair Encoding](https://en.wikipedia.org/wiki/Byte_pair_encoding) tokeniser for use with OpenAI's models. It is useful for when we wish to know how many tokens our message would be in the model's vocabulary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can install these libraries using conda like so:\n",
    "\n",
    "```bash\n",
    "conda install -c conda-forge \\\n",
    "    langchain \\ \n",
    "    openai \\\n",
    "    datasets \\\n",
    "    tiktoken\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, pinecone-client is not yet available on conda-forge, so we will need to resort to using pip\n",
    "\n",
    "```bash\n",
    "pip install pinecone-client\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Chatbot (no RAG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be relying heavily on the LangChain library to bring together the different components needed for our chatbot. To begin, we'll create a simple chatbot without any retrieval augmentation. We do this by initializing a `ChatOpenAI` object. For this we do need an [OpenAI API key](https://platform.openai.com/account/api-keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key= OPENAI_API_KEY,\n",
    "    model='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chats with OpenAI's `gpt-3.5-turbo` and `gpt-4` chat models are typically [structured (in plain text) like this](https://help.openai.com/en/articles/7042661-chatgpt-api-transition-guide):\n",
    "\n",
    "```\n",
    "System: You are a helpful assistant.\n",
    "\n",
    "User: Hi AI, how are you today?\n",
    "\n",
    "Assistant: I'm great thank you. How can I help you?\n",
    "\n",
    "User: I'd like to understand string theory.\n",
    "\n",
    "Assistant:\n",
    "```\n",
    "\n",
    "The final `\"Assistant:\"` without a response is what would prompt the model to continue the conversation. In the official OpenAI `ChatCompletion` endpoint these would be passed to the model in a format like:\n",
    "\n",
    "```python\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi AI, how are you today?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I'm great thank you. How can I help you?\"}\n",
    "    {\"role\": \"user\", \"content\": \"I'd like to understand string theory.\"}\n",
    "]\n",
    "```\n",
    "\n",
    "In LangChain there is a slightly different format. We use three _message_ objects like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
    "    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
    "    HumanMessage(content=\"I'd like to understand string theory.\")\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format is very similar, we're just swapped the role of `\"user\"` for `HumanMessage`, and the role of `\"assistant\"` for `AIMessage`.\n",
    "\n",
    "> NOTE: You may ask,  why LangChain would both changing these? Keep in mind that LangChain is remaining agnostic as to which is the best service (be it LLM's, Vector Stores, etc.). Therefore, LangChain 'wraps' the messages in a `HumanMessage` or `AIMessage` object to indicate which is which. This allows us to easily swap out the AI service without having to change the message format. LangChain would handle any required translation to the new service's format.\n",
    "\n",
    "```python\n",
    "[\n",
    "    HumanMessage(\"You are a helpful assistant.\"),\n",
    "    HumanMessage(\"Hi AI, how are you today?\"),\n",
    "    AIMessage(\"I'm great thank you. How can I help you?\")\n",
    "    HumanMessage(\"I'd like to understand string theory.\")\n",
    "]\n",
    "```\n",
    "\n",
    "We generate the next response from the AI by passing these messages to the `ChatOpenAI` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"String theory is a theoretical framework in physics that attempts to explain the fundamental nature of particles and the interactions between them. It suggests that particles are not point-like objects but instead tiny, vibrating strings of energy. These strings can vibrate at different frequencies, giving rise to different types of particles.\\n\\nHere are some key points to understand about string theory:\\n\\n1. Dimensions: String theory requires more than the usual three dimensions of space and one dimension of time. In fact, it suggests the existence of additional dimensions beyond our everyday experience. The most well-known version of string theory, called superstring theory, suggests that there are 10 dimensions in total (9 spatial dimensions and 1 time dimension).\\n\\n2. Unification of forces: String theory aims to unify the fundamental forces of nature, including gravity, electromagnetism, and the strong and weak nuclear forces. In traditional physics, these forces are described by separate theories, but string theory proposes that they are all different manifestations of a single underlying framework.\\n\\n3. Quantum mechanics: String theory incorporates the principles of quantum mechanics, which describe the behavior of particles on a very small scale. It introduces the concept of quantization, where physical quantities like energy and momentum can only exist in discrete, quantized values.\\n\\n4. Multiple versions: There are different versions of string theory, such as Type I, Type IIA, Type IIB, heterotic SO(32), and heterotic E8×E8. These versions have different properties but are believed to be related through a process called duality.\\n\\n5. Challenges and ongoing research: String theory is still a subject of active research and is not yet experimentally confirmed. It faces several challenges, including the difficulty of testing its predictions and the lack of a unique solution that describes our observed universe. However, it has provided valuable insights and connections to other areas of physics.\\n\\nIt's important to note that string theory can be a complex and mathematically demanding field. This explanation provides a general overview, but delving deeper into the subject may require a solid understanding of advanced mathematics and physics.\")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = chat(messages)\n",
    "res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In response we get another AI message object. We can print it more clearly like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String theory is a theoretical framework in physics that attempts to explain the fundamental nature of particles and the interactions between them. It suggests that particles are not point-like objects but instead tiny, vibrating strings of energy. These strings can vibrate at different frequencies, giving rise to different types of particles.\n",
      "\n",
      "Here are some key points to understand about string theory:\n",
      "\n",
      "1. Dimensions: String theory requires more than the usual three dimensions of space and one dimension of time. In fact, it suggests the existence of additional dimensions beyond our everyday experience. The most well-known version of string theory, called superstring theory, suggests that there are 10 dimensions in total (9 spatial dimensions and 1 time dimension).\n",
      "\n",
      "2. Unification of forces: String theory aims to unify the fundamental forces of nature, including gravity, electromagnetism, and the strong and weak nuclear forces. In traditional physics, these forces are described by separate theories, but string theory proposes that they are all different manifestations of a single underlying framework.\n",
      "\n",
      "3. Quantum mechanics: String theory incorporates the principles of quantum mechanics, which describe the behavior of particles on a very small scale. It introduces the concept of quantization, where physical quantities like energy and momentum can only exist in discrete, quantized values.\n",
      "\n",
      "4. Multiple versions: There are different versions of string theory, such as Type I, Type IIA, Type IIB, heterotic SO(32), and heterotic E8×E8. These versions have different properties but are believed to be related through a process called duality.\n",
      "\n",
      "5. Challenges and ongoing research: String theory is still a subject of active research and is not yet experimentally confirmed. It faces several challenges, including the difficulty of testing its predictions and the lack of a unique solution that describes our observed universe. However, it has provided valuable insights and connections to other areas of physics.\n",
      "\n",
      "It's important to note that string theory can be a complex and mathematically demanding field. This explanation provides a general overview, but delving deeper into the subject may require a solid understanding of advanced mathematics and physics.\n",
      "\n",
      "NOTE: res is an AIMessage object from LangChain:\n",
      "<class 'langchain.schema.messages.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(res.content)\n",
    "print('\\nNOTE: res is an AIMessage object from LangChain:')\n",
    "print(type(res))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `res` is just another `AIMessage` object, we can append it to `messages`, add another `HumanMessage`, and generate the next response in the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physicists believe that string theory has the potential to produce a unified theory because it incorporates all the fundamental forces of nature within a single framework. This unification is desirable because it would provide a more complete understanding of the fundamental building blocks of the universe and the interactions between them.\n",
      "\n",
      "Here are a few reasons why physicists are hopeful about string theory's potential for unification:\n",
      "\n",
      "1. Consistency with quantum mechanics: String theory is inherently a quantum theory, meaning it incorporates the principles of quantum mechanics. Quantum mechanics has been incredibly successful in describing the behavior of particles on a small scale, so it is natural to seek a theory that unifies quantum mechanics with gravity (which is described by general relativity).\n",
      "\n",
      "2. Gravity as a force-carrying particle: In string theory, the graviton emerges as a vibration mode of the string. This suggests that gravity is not fundamentally different from other forces, but rather another manifestation of the vibrating strings. This viewpoint aligns with the idea of unification, treating gravity as a force on equal footing with the other forces.\n",
      "\n",
      "3. Duality and interconnectedness: String theory exhibits various dualities, which relate different versions of the theory to one another. These dualities suggest that seemingly different theories are actually different descriptions of the same underlying physics. This interconnectedness is a promising indication that a unified theory may exist.\n",
      "\n",
      "4. Resolution of inconsistencies: String theory has the potential to resolve some long-standing inconsistencies in physics, such as the incompatibility between general relativity and quantum mechanics. It provides a framework where both theories can coexist and be reconciled.\n",
      "\n",
      "It's important to note that while physicists are optimistic about the potential of string theory, it has not yet been experimentally verified, and many challenges and questions remain. However, the pursuit of a unified theory continues to drive research in string theory and related areas.\n"
     ]
    }
   ],
   "source": [
    "# add latest AI response to messages\n",
    "messages.append(res)\n",
    "\n",
    "# now create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=\"Why do physicists believe it can produce a 'unified theory'?\"\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to chat-gpt\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the messages list is not 8 items long. This is because we are storing the sequence of LangChain messages so that we can use these to provide content when sending a prompt to out LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant.'),\n",
       " HumanMessage(content='Hi AI, how are you today?'),\n",
       " AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
       " HumanMessage(content=\"I'd like to understand string theory.\"),\n",
       " AIMessage(content=\"String theory is a theoretical framework in physics that attempts to explain the fundamental nature of particles and the interactions between them. It suggests that particles are not point-like objects but instead tiny, vibrating strings of energy. These strings can vibrate at different frequencies, giving rise to different types of particles.\\n\\nHere are some key points to understand about string theory:\\n\\n1. Dimensions: String theory requires more than the usual three dimensions of space and one dimension of time. In fact, it suggests the existence of additional dimensions beyond our everyday experience. The most well-known version of string theory, called superstring theory, suggests that there are 10 dimensions in total (9 spatial dimensions and 1 time dimension).\\n\\n2. Unification of forces: String theory aims to unify the fundamental forces of nature, including gravity, electromagnetism, and the strong and weak nuclear forces. In traditional physics, these forces are described by separate theories, but string theory proposes that they are all different manifestations of a single underlying framework.\\n\\n3. Quantum mechanics: String theory incorporates the principles of quantum mechanics, which describe the behavior of particles on a very small scale. It introduces the concept of quantization, where physical quantities like energy and momentum can only exist in discrete, quantized values.\\n\\n4. Multiple versions: There are different versions of string theory, such as Type I, Type IIA, Type IIB, heterotic SO(32), and heterotic E8×E8. These versions have different properties but are believed to be related through a process called duality.\\n\\n5. Challenges and ongoing research: String theory is still a subject of active research and is not yet experimentally confirmed. It faces several challenges, including the difficulty of testing its predictions and the lack of a unique solution that describes our observed universe. However, it has provided valuable insights and connections to other areas of physics.\\n\\nIt's important to note that string theory can be a complex and mathematically demanding field. This explanation provides a general overview, but delving deeper into the subject may require a solid understanding of advanced mathematics and physics.\"),\n",
       " HumanMessage(content=\"Why do physicists believe it can produce a 'unified theory'?\")]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Hallucinations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our chatbot, but as mentioned — the knowledge of LLMs can be limited. The reason for this is that LLMs learn all they know during training. An LLM essentially compresses the \"world\" as seen in the training data into the internal parameters of the model. We call this knowledge the _parametric knowledge_ of the model.\n",
    "\n",
    "By default, LLMs have no access to the external world.\n",
    "\n",
    "The result of this is very clear when we ask LLMs about more recent information, like about the new (and very popular) [Llama 2 LLM](https://ai.meta.com/llama/) (I've mentioned Llama and Llama 2 in class - it's an opensource LLM developed by Meta/Facebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add latest AI response to messages\n",
    "messages.append(res)\n",
    "\n",
    "# now create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=\"What is so special about Llama 2?\"\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to OpenAI\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize, but I couldn't find any specific information about something called \"Llama 2.\" It's possible that you may be referring to something that is not widely known or that is specific to a particular context. If you can provide more details or clarify your question, I'll do my best to assist you.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our chatbot can no longer help us, it doesn't contain the information we need to answer the question. It was very clear from this answer that the LLM doesn't know the informaiton, but sometimes an LLM may respond like it _does_ know the answer — and, somtetimes, this can difficult to detect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add latest AI response to messages\n",
    "messages.append(res)\n",
    "\n",
    "# now create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=\"Can you tell me about the prerequisites for University of South Florida's MSBAIS program?\"\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to OpenAI\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To provide accurate information about the prerequisites for the University of South Florida's MSBAIS (Master of Science in Business Analytics and Information Systems) program, it is best to refer directly to the university's official website or contact the admissions office. However, I can provide you with some general information about typical prerequisites for similar programs:\n",
      "\n",
      "1. Educational Background: Most MSBAIS programs require applicants to hold a bachelor's degree from an accredited institution. The preferred undergraduate degree may vary, but it is often in a field related to business, computer science, information systems, mathematics, statistics, or a related discipline.\n",
      "\n",
      "2. Academic Requirements: Applicants are typically expected to have a competitive undergraduate GPA. The specific minimum GPA requirement can vary between institutions, but a strong academic record is generally preferred.\n",
      "\n",
      "3. Coursework: Some programs may require specific prerequisite coursework or foundational knowledge in areas such as mathematics (e.g., calculus, linear algebra, probability), statistics, programming, database management, or business fundamentals. However, this can vary depending on the program, so it's essential to review the specific requirements of the University of South Florida's MSBAIS program.\n",
      "\n",
      "4. Standardized Test Scores: Many programs require applicants to submit scores from standardized tests like the GRE (Graduate Record Examination) or GMAT (Graduate Management Admission Test). However, some programs may waive these requirements or provide alternatives, so it's important to check the program's specific guidelines.\n",
      "\n",
      "5. Work Experience: While work experience is not always a prerequisite for MSBAIS programs, some programs may prefer or require applicants to have relevant professional experience, particularly for executive or part-time programs. The University of South Florida's MSBAIS program may have specific guidelines regarding work experience, so it's advisable to review their requirements.\n",
      "\n",
      "Remember that these prerequisites are general guidelines, and the University of South Florida's MSBAIS program may have additional or different requirements. It is always best to refer to the official program website or contact the admissions office directly for the most accurate and up-to-date information.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another way of feeding knowledge into LLMs. It is called _source knowledge_ and it refers to any information fed into the LLM via the prompt. We can try that with the MSBAIS' program's prereq question. We can take a description of this from the MSBAIS program website (https://catalog.usf.edu/preview_program.php?catoid=12&poid=3955&returnto=2049)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_knowledge = \"\"\"\n",
    "\n",
    "CURRICULUM REQUIREMENTS\n",
    "Total Minimum Hours: 33 credit hours\n",
    "\n",
    "Core Requirements– 12 credit hours\n",
    "Capstone – 3 credit hours\n",
    "Concentration or Electives – 18 credit hours\n",
    "The major requires 33 hours of coursework and may be taken either full-time or part-time. Full-time students with appropriate prerequisites may be able to complete the major in one full year (3 semesters) of study. Part-time students and full-time students who need prerequisites will typically need from 1 ½ to 3 years to complete the degree.\n",
    "\n",
    "Prerequisites\n",
    "Incoming students are expected to have the following as prerequisites\n",
    "\n",
    "A course in high-level, object oriented programming language (e.g., C#, C++, Java and Python) or substantial programming experience;\n",
    "A course in Information Systems Analysis and Design or equivalent experience;\n",
    "A course in Database Systems or equivalent experience;\n",
    "A course in Statistics or equivalent professional qualification or experiences\n",
    "A course in economics, or equivalent professional qualification or experiences and\n",
    "A course in financial accounting.\n",
    "These required prerequisite courses may be taken simultaneously with courses in the M.S./BAIS major. Prerequisiite courses do not count toward the 33 credit hours of course requirements in the M.S./BAIS major.\n",
    "\n",
    "Students have the choice of two options:\n",
    "\n",
    "On-Campus Option:\n",
    "Designed for students who need flexibility in their course work, students will work early in the first semester with their major advisor to complete a formal Major Curriculum of Study meeting the Major Curriculum Requirements that will define a coherent sequence of courses to accomplish the student’s objectives. Students have choice of electives as well as the option to complete a master’s thesis or practicum project, depending upon the availability and approval of a faculty sponsor.\n",
    "\n",
    "Executive Weekend Option:\n",
    "Intended for full-time working Information Technology/Information Systems/Business professionals who will pursue this degree while remaining employed. Offered on a cohort basis, students will meet the Major Curriculum Requirements through a pre-determined set of courses, electives, and independent study options selected by faculty and noted on the formal Major Curriculum of Study, based on market needs and student profiles. Students will benefit from an accelerated curriculum with a managerial and leadership approach. To get the full benefit, applicants are expected to have a minimum of 5 years of relevant work experience.\n",
    "\n",
    "CORE REQUIREMENTS (12 CREDIT HOURS)\n",
    "The following four courses provide an understanding of the state-of-the-art in research and practice in technical areas of Information Systems Management.\n",
    "\n",
    "ISM 6124 Advanced Systems Analysis and Design Credit Hours: 3\n",
    "ISM 6218 Advanced Database Management Credit Hours: 3\n",
    "ISM 6225 Distributed Information Systems Credit Hours: 3\n",
    "QMB 6304 Analytical Methods for Business Credit Hours: 3\n",
    "CAPSTONE COURSE (3 CREDIT HOURS)\n",
    "This course is considered the capstone of the M.S./BAIS major and as such it must be taken during one of the last two semesters of the student’s major.\n",
    "\n",
    "ISM 6155 Enterprise Information Systems Management Credit Hours: 3\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can feed this additional knowledge into our prompt with some instructions telling the LLM how we'd like it to use this information alongside our original query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Can you tell me about the prerequisites for University of South Florida's MSBAIS program?\"\n",
    "\n",
    "augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "Contexts:\n",
    "{source_knowledge}\n",
    "\n",
    "Query: {query}\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we feed this into our chatbot as we were before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=augmented_prompt\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to OpenAI\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prerequisites for the University of South Florida's MSBAIS (Master of Science in Business Analytics and Information Systems) program are as follows:\n",
      "\n",
      "1. A course in high-level, object-oriented programming language (e.g., C#, C++, Java, and Python) or substantial programming experience.\n",
      "2. A course in Information Systems Analysis and Design or equivalent experience.\n",
      "3. A course in Database Systems or equivalent experience.\n",
      "4. A course in Statistics or equivalent professional qualification or experiences.\n",
      "5. A course in economics or equivalent professional qualification or experiences.\n",
      "6. A course in financial accounting.\n",
      "\n",
      "These prerequisites are expected to be completed before or concurrently with the courses in the MSBAIS major. It's worth noting that these prerequisite courses do not count toward the 33 credit hours required for the MSBAIS major.\n",
      "\n",
      "The program offers two options for students: the On-Campus Option and the Executive Weekend Option.\n",
      "\n",
      "In the On-Campus Option, students work with their major advisor early in the first semester to create a Major Curriculum of Study that meets the program's requirements. Students have elective choices and the option to complete a master's thesis or practicum project, subject to faculty approval.\n",
      "\n",
      "The Executive Weekend Option is designed for full-time working professionals in the IT/IS/Business field. It follows a cohort model, and the curriculum is pre-determined based on market needs and student profiles. This option offers an accelerated curriculum with a managerial and leadership approach, and applicants are expected to have a minimum of 5 years of relevant work experience.\n",
      "\n",
      "The core requirements for the MSBAIS program are as follows:\n",
      "\n",
      "- ISM 6124 Advanced Systems Analysis and Design (3 credit hours)\n",
      "- ISM 6218 Advanced Database Management (3 credit hours)\n",
      "- ISM 6225 Distributed Information Systems (3 credit hours)\n",
      "- QMB 6304 Analytical Methods for Business (3 credit hours)\n",
      "\n",
      "Additionally, the program includes a capstone course that must be taken during one of the last two semesters:\n",
      "\n",
      "- ISM 6155 Enterprise Information Systems Management (3 credit hours)\n",
      "\n",
      "These courses provide an understanding of the state-of-the-art research and practice in technical areas of Information Systems Management.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality of this answer is excellent. This is made possible because we have augmented our query with external knowledge (source knowledge). There's just one problem — how do we get this information in the first place?\n",
    "\n",
    "We learned in a previous class about Pinecone and vector databases. Let's use a Pinecone vector database. But first, we'll need a dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, we will be importing our data. We will be using the Hugging Face Datasets library to load our data. Specifically, we will be using the `\"jamescalam/llama-2-arxiv-papers\"` dataset. This dataset contains a collection of ArXiv papers which will serve as the external knowledge base for our chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 409/409 [00:00<?, ?B/s] \n",
      "Downloading data: 100%|██████████| 14.4M/14.4M [00:01<00:00, 12.2MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 166.69it/s]\n",
      "Generating train split: 4838 examples [00:00, 44631.93 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['doi', 'chunk-id', 'chunk', 'id', 'title', 'summary', 'source', 'authors', 'categories', 'comment', 'journal_ref', 'primary_category', 'published', 'updated', 'references'],\n",
       "    num_rows: 4838\n",
       "})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"jamescalam/llama-2-arxiv-papers-chunked\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: We could also write a screen scaper to search for and download papers on a certain topic -- or download these by hand and store as pdf's or text. There are many other possible sources of information on a given topic -- for instance, USF's MSBAIS program has web pages, course descriptions, and other information that could be used as a knowledge base. Also, depending on the business processes you are attempting to automate, you may need to collect documents external to USF - such as information about tampa, lodging, visa applications, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doi': '1102.0183',\n",
       " 'chunk-id': '0',\n",
       " 'chunk': 'High-Performance Neural Networks\\nfor Visual Object Classi\\x0ccation\\nDan C. Cire\\x18 san, Ueli Meier, Jonathan Masci,\\nLuca M. Gambardella and J\\x7f urgen Schmidhuber\\nTechnical Report No. IDSIA-01-11\\nJanuary 2011\\nIDSIA / USI-SUPSI\\nDalle Molle Institute for Arti\\x0ccial Intelligence\\nGalleria 2, 6928 Manno, Switzerland\\nIDSIA is a joint institute of both University of Lugano (USI) and University of Applied Sciences of Southern Switzerland (SUPSI),\\nand was founded in 1988 by the Dalle Molle Foundation which promoted quality of life.\\nThis work was partially supported by the Swiss Commission for Technology and Innovation (CTI), Project n. 9688.1 IFF:\\nIntelligent Fill in Form.arXiv:1102.0183v1  [cs.AI]  1 Feb 2011\\nTechnical Report No. IDSIA-01-11 1\\nHigh-Performance Neural Networks\\nfor Visual Object Classi\\x0ccation\\nDan C. Cire\\x18 san, Ueli Meier, Jonathan Masci,\\nLuca M. Gambardella and J\\x7f urgen Schmidhuber\\nJanuary 2011\\nAbstract\\nWe present a fast, fully parameterizable GPU implementation of Convolutional Neural\\nNetwork variants. Our feature extractors are neither carefully designed nor pre-wired, but',\n",
       " 'id': '1102.0183',\n",
       " 'title': 'High-Performance Neural Networks for Visual Object Classification',\n",
       " 'summary': 'We present a fast, fully parameterizable GPU implementation of Convolutional\\nNeural Network variants. Our feature extractors are neither carefully designed\\nnor pre-wired, but rather learned in a supervised way. Our deep hierarchical\\narchitectures achieve the best published results on benchmarks for object\\nclassification (NORB, CIFAR10) and handwritten digit recognition (MNIST), with\\nerror rates of 2.53%, 19.51%, 0.35%, respectively. Deep nets trained by simple\\nback-propagation perform better than more shallow ones. Learning is\\nsurprisingly rapid. NORB is completely trained within five epochs. Test error\\nrates on MNIST drop to 2.42%, 0.97% and 0.48% after 1, 3 and 17 epochs,\\nrespectively.',\n",
       " 'source': 'http://arxiv.org/pdf/1102.0183',\n",
       " 'authors': ['Dan C. Cireşan',\n",
       "  'Ueli Meier',\n",
       "  'Jonathan Masci',\n",
       "  'Luca M. Gambardella',\n",
       "  'Jürgen Schmidhuber'],\n",
       " 'categories': ['cs.AI', 'cs.NE'],\n",
       " 'comment': '12 pages, 2 figures, 5 tables',\n",
       " 'journal_ref': None,\n",
       " 'primary_category': 'cs.AI',\n",
       " 'published': '20110201',\n",
       " 'updated': '20110201',\n",
       " 'references': []}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Overview\n",
    "\n",
    "The dataset we are using is sourced from the Llama 2 ArXiv papers. It is a collection of academic papers from ArXiv, a repository of electronic preprints approved for publication after moderation. Each entry in the dataset represents a \"chunk\" of text from these papers.\n",
    "\n",
    "Because most **L**arge **L**anguage **M**odels (LLMs) only contain knowledge of the world as it was during training, they cannot answer our questions about Llama 2 — at least not without this data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Building the Knowledge Base"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dataset that can serve as our chatbot knowledge base. Our next task is to transform that dataset into the knowledge base that our chatbot can use. To do this we must use an embedding model and vector database.\n",
    "\n",
    "We begin by initializing our connection to Pinecone, this requires a [free API key](https://app.pinecone.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "# get API key from app.pinecone.io and environment from console\n",
    "pinecone.init(\n",
    "    api_key=os.environ.get('PINECONE_API_KEY') or 'YOUR_API_KEY',\n",
    "    environment=os.environ.get('PINECONE_ENVIRONMENT') or 'YOUR_ENV'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we initialize the index. We will be using OpenAI's `text-embedding-ada-002` model for creating the embeddings, so we set the `dimension` to `1536`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most (all?) of you are using the free version of Pinecone. Though this will be sufficient to hold the data required for you course work, the free services is limited to only one index at a time. Therefore, we will need to delete the index if we wish to create a new one.\n",
    "\n",
    "First, let's look at what indexes we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rag-index']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will remove all existing indexes from your pinecone account. **Only run this if you are sure you want to delete all indexes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = pinecone.list_indexes()\n",
    "while len(index_list) > 0:\n",
    "    pinecone.delete_index(index_list[-1])\n",
    "    index_list = pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create our pinecone index. We should wait to make sure it is ready before we use it before moving to the next cell. The while loop will check the status of the index every second until it is ready...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "if PINECONE_INDEX_NAME not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        PINECONE_INDEX_NAME,\n",
    "        dimension=1536,\n",
    "        metric='cosine'\n",
    "    )\n",
    "    # wait for index to finish initialization\n",
    "    while not pinecone.describe_index(PINECONE_INDEX_NAME).status['ready']:\n",
    "        time.sleep(1)\n",
    "        \n",
    "\n",
    "index = pinecone.Index(PINECONE_INDEX_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we connect to the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our index is now ready but it's empty. It is a vector index, so it needs vectors. As mentioned, to create these vector embeddings we will OpenAI's `text-embedding-ada-002` model — we can access it via LangChain like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this model we can create embeddings like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1536)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    'this is the first chunk of text',\n",
    "    'then another second chunk of text is here'\n",
    "]\n",
    "\n",
    "res = embed_model.embed_documents(texts)\n",
    "len(res), len(res[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we get two (aligning to our two chunks of text) 1536-dimensional embeddings.\n",
    "\n",
    "We're now ready to embed and index all our our data! We do this by looping through our dataset and embedding and inserting everything in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:59<00:00,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm  # for progress bar\n",
    "\n",
    "data = dataset.to_pandas()  # this makes it easier to iterate over the dataset\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    i_end = min(len(data), i+batch_size)\n",
    "    # get batch of data\n",
    "    batch = data.iloc[i:i_end]\n",
    "    # generate unique ids for each chunk\n",
    "    ids = [f\"{x['doi']}-{x['chunk-id']}\" for i, x in batch.iterrows()]\n",
    "    # get text to embed\n",
    "    texts = [x['chunk'] for _, x in batch.iterrows()]\n",
    "    # embed text\n",
    "    embeds = embed_model.embed_documents(texts)\n",
    "    # get metadata to store in Pinecone\n",
    "    metadata = [\n",
    "        {'text': x['chunk'],\n",
    "         'source': x['source'],\n",
    "         'title': x['title']} for i, x in batch.iterrows()\n",
    "    ]\n",
    "    # add to Pinecone\n",
    "    index.upsert(vectors=zip(ids, embeds, metadata))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that the vector index has been populated using `describe_index_stats` like before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.038,\n",
       " 'namespaces': {'': {'vector_count': 3800}},\n",
       " 'total_vector_count': 3800}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieval Augmented Generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've built a fully-fledged knowledge base. Now it's time to connect that knowledge base to our chatbot. To do that we'll be diving back into LangChain and reusing our template prompt from earlier."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use LangChain here we need to load the LangChain abstraction for a vector index, called a `vectorstore`. We pass in our vector `index` to initialize the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tcsmi\\miniconda3\\envs\\ta\\Lib\\site-packages\\langchain\\vectorstores\\pinecone.py:59: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"text\"  # the metadata field that contains our text\n",
    "\n",
    "# initialize the vector store object\n",
    "vectorstore = Pinecone(\n",
    "    index, embed_model.embed_query, text_field\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this `vectorstore` we can already query the index and see if we have any relevant information given our question about Llama 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Alan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom\\x03\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and ﬁne-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur ﬁne-tuned LLMs, called L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosedsource models. We provide a detailed description of our approach to ﬁne-tuning and safety', metadata={'source': 'http://arxiv.org/pdf/2307.09288', 'title': 'Llama 2: Open Foundation and Fine-Tuned Chat Models'}),\n",
       " Document(page_content='asChatGPT,BARD,andClaude. TheseclosedproductLLMsareheavilyﬁne-tunedtoalignwithhuman\\npreferences, which greatly enhances their usability and safety. This step can require signiﬁcant costs in\\ncomputeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\\nthe community to advance AI alignment research.\\nIn this work, we develop and release Llama 2, a family of pretrained and ﬁne-tuned LLMs, L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle and\\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc models generally perform better than existing open-source models. They also appear to\\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see', metadata={'source': 'http://arxiv.org/pdf/2307.09288', 'title': 'Llama 2: Open Foundation and Fine-Tuned Chat Models'}),\n",
       " Document(page_content='Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aur’elien Rodriguez, Armand Joulin, Edouard\\nGrave, and Guillaume Lample. Llama: Open and eﬃcient foundation language models. arXiv preprint\\narXiv:2302.13971 , 2023.\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser,\\nand Illia Polosukhin. Attention is all you need, 2017.\\nOriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung,\\nDavid H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, et al. Grandmaster level in starcraft ii using\\nmulti-agent reinforcement learning. Nature, 575(7782):350–354, 2019.\\nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and HannanehHajishirzi. Self-instruct: Aligninglanguagemodel withselfgeneratedinstructions. arXivpreprint', metadata={'source': 'http://arxiv.org/pdf/2307.09288', 'title': 'Llama 2: Open Foundation and Fine-Tuned Chat Models'})]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is Llama 2?\"\n",
    "\n",
    "vectorstore.similarity_search(query, k=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We return a lot of text here and it's not that clear what we need or what is relevant. Fortunately, our LLM will be able to parse this information much faster than us. All we need is to connect the output from our `vectorstore` to our `chat` chatbot. To do that we can use the same logic as we used earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_prompt(query: str):\n",
    "    # get top 3 results from knowledge base\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    # get the text from the results\n",
    "    source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
    "    # feed into an augmented prompt\n",
    "    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "    Contexts:\n",
    "    {source_knowledge}\n",
    "\n",
    "    Query: {query}\"\"\"\n",
    "    return augmented_prompt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this we produce an augmented prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the contexts below, answer the query.\n",
      "\n",
      "    Contexts:\n",
      "    Alan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\n",
      "Ross Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\n",
      "Angela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\n",
      "Sergey Edunov Thomas Scialom\u0003\n",
      "GenAI, Meta\n",
      "Abstract\n",
      "In this work, we develop and release Llama 2, a collection of pretrained and ﬁne-tuned\n",
      "large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\n",
      "Our ﬁne-tuned LLMs, called L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc , are optimized for dialogue use cases. Our\n",
      "models outperform open-source chat models on most benchmarks we tested, and based on\n",
      "ourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosedsource models. We provide a detailed description of our approach to ﬁne-tuning and safety\n",
      "asChatGPT,BARD,andClaude. TheseclosedproductLLMsareheavilyﬁne-tunedtoalignwithhuman\n",
      "preferences, which greatly enhances their usability and safety. This step can require signiﬁcant costs in\n",
      "computeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\n",
      "the community to advance AI alignment research.\n",
      "In this work, we develop and release Llama 2, a family of pretrained and ﬁne-tuned LLMs, L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle and\n",
      "L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\n",
      "L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc models generally perform better than existing open-source models. They also appear to\n",
      "be on par with some of the closed-source models, at least on the human evaluations we performed (see\n",
      "Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aur’elien Rodriguez, Armand Joulin, Edouard\n",
      "Grave, and Guillaume Lample. Llama: Open and eﬃcient foundation language models. arXiv preprint\n",
      "arXiv:2302.13971 , 2023.\n",
      "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser,\n",
      "and Illia Polosukhin. Attention is all you need, 2017.\n",
      "Oriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung,\n",
      "David H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, et al. Grandmaster level in starcraft ii using\n",
      "multi-agent reinforcement learning. Nature, 575(7782):350–354, 2019.\n",
      "Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and HannanehHajishirzi. Self-instruct: Aligninglanguagemodel withselfgeneratedinstructions. arXivpreprint\n",
      "\n",
      "    Query: What is Llama 2?\n"
     ]
    }
   ],
   "source": [
    "print(augment_prompt(query))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still a lot of text here, so let's pass it onto our chat model to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 2 is a collection of pretrained and fine-tuned large language models (LLMs) developed and released in a research work. These LLMs range in scale from 7 billion to 70 billion parameters. They are optimized for dialogue use cases and are specifically designed for chat conversations. The models, named L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc , have been fine-tuned to perform well on various benchmarks and have shown better performance compared to existing open-source chat models in most cases. The research work also suggests that these models may be suitable alternatives to closed-source models, based on evaluations of helpfulness and safety.\n",
      "\n",
      "It is worth noting that the Llama 2 models are part of ongoing research and development in the field of language models and their application in dialogue systems. The work describes the approach used for fine-tuning the models and emphasizes the importance of transparency and reproducibility in AI alignment research.\n"
     ]
    }
   ],
   "source": [
    "# create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=augment_prompt(query)\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...The performance of this is rather surprising - notice how the chatbot was able to make some sense out of this text -- and the text contained many issues, like missing spaces between words."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can continue with more Llama 2 questions. Let's try _without_ RAG first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the provided context, it is mentioned that Llama 2, a collection of pretrained and fine-tuned large language models (LLMs), was developed with a focus on safety. However, the specific safety measures used in the development of Llama 2 are not detailed in the available information. Without further context or additional information, it is not possible to provide specific details about the safety measures employed in the development of Llama 2.\n"
     ]
    }
   ],
   "source": [
    "prompt = HumanMessage(\n",
    "    content=\"what safety measures were used in the development of llama 2?\"\n",
    ")\n",
    "\n",
    "res = chat(messages + [prompt])\n",
    "print(res.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chatbot is able to respond about Llama 2 thanks to it's conversational history stored in `messages`. However, it doesn't know anything about the safety measures themselves as we have not provided it with that information via the RAG pipeline. Let's try again but with RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the development of Llama 2, several safety measures were employed to increase the safety of the models. These measures include:\n",
      "\n",
      "1. Safety-specific data annotation and tuning: During the fine-tuning process, specific attention was given to safety-related aspects. The models were trained and fine-tuned using data that was annotated with safety considerations in mind. This approach helps enhance the models' ability to generate safe and appropriate responses.\n",
      "\n",
      "2. Red-teaming: Red-teaming involves conducting critical evaluations and assessments of the models. This process involves having external experts or teams challenge the models and identify potential safety risks or vulnerabilities. By subjecting the models to rigorous evaluations, any issues or areas of concern can be identified and addressed.\n",
      "\n",
      "3. Iterative evaluations: The development of Llama 2 involved iterative evaluations. This means that the models were continuously assessed and improved based on feedback and evaluations. This iterative process allows for the identification and mitigation of safety-related issues over time.\n",
      "\n",
      "By implementing these safety measures, the developers aimed to enhance the safety of Llama 2. The goal was to ensure that the models generated responses that were helpful, appropriate, and aligned with human preferences. The openness and transparency in describing the fine-tuning methodology and safety approach also aim to enable the broader community to reproduce and further improve the safety of Llama 2 and similar models.\n"
     ]
    }
   ],
   "source": [
    "prompt = HumanMessage(\n",
    "    content=augment_prompt(\n",
    "        \"what safety measures were used in the development of llama 2?\"\n",
    "    )\n",
    ")\n",
    "\n",
    "res = chat(messages + [prompt])\n",
    "print(res.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a much more informed response that includes several items missing in the previous non-RAG response, such as \"red-teaming\", \"iterative evaluations\", and the intention of the researchers to share this research to help \"improve their safety, promoting responsible development in the field\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For your final project\n",
    "\n",
    "As you can see from the above examples, successful utilization of RAG requires a lot of work. You will need to: \n",
    "\n",
    "* Find data sources that contain information related to the process(es) you are trying to support\n",
    "* Create a suitable knowledgebase by embedding and indexing the data\n",
    "* Create a suitable prompt that can be used to query the knowledgebase\n",
    "* Create a suitable chatbot that can be used to interact with the user\n",
    "* Connect the chatbot to the knowledgebase via the prompt\n",
    "* Test the chatbot to ensure it is working as expected\n",
    "* Iterate on the above steps until you have a working chatbot\n",
    "\n",
    "LangChain has a number of powerful and userful document loaders. You can read entire directories of files, or specific files. [You can easily import JSON files, CSV files, PDF Files, HTML files, and Markdown](https://python.langchain.com/docs/modules/data_connection/document_loaders.html). You can also access live databases/datasources using [Retrievers](https://python.langchain.com/docs/modules/data_connection/retrievers/) (BUT, accessing a live datasource not needed for your final project)\n",
    "\n",
    "```python\n",
    "\n",
    "# there are usually multiple ways to load data into LangChain\n",
    "\n",
    "####\n",
    "# load a single pdf\n",
    "#load single pdf and split into text chunks\n",
    "#loader = PyPDFLoader(\"./pdfs/paper1.pdf\")\n",
    "\n",
    "####\n",
    "# load a directory of pdf files\n",
    "#loader = PyPDFDirectoryLoader(\"./pdfs\")\n",
    "\n",
    "\n",
    "# load all pdfs from a folder, using directory loader\n",
    "# and PyPDFLoader to load each pdf. You can replace\n",
    "# PyPDFLoader with any other loader that you need\n",
    "# such as...\n",
    "# JSON loader (https://python.langchain.com/docs/modules/data_connection/document_loaders/json)\n",
    "# HTML loader (https://python.langchain.com/docs/modules/data_connection/document_loaders/html)\n",
    "# CSV loader https://python.langchain.com/docs/modules/data_connection/document_loaders/csv\n",
    "# Markdown loader https://python.langchain.com/docs/modules/data_connection/document_loaders/markdown\n",
    "loader = DirectoryLoader(\n",
    "    '../', \n",
    "    glob=\"**/*.md\", \n",
    "    use_multithreading=True,\n",
    "    loader_cls=PyPDFLoader,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "# once the loader is defined, we can load our documents\n",
    "docs = loader.load()\n",
    "\n",
    "# then split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=100\n",
    ")\n",
    "texts = text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "The final piece of this puzzle is how to create a \"chatbot\" user interface. This is covered in the next notebook.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redacre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
