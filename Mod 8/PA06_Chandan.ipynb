{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PA06\n",
        "\n",
        "# Author: Chandan Patel \n",
        "\n",
        "This notebook demonstrates the use of the LangChain .\n",
        "1. Calling a LLM to get answer\n",
        "2. Calling a ChatGPT to get answer\n",
        "3. Using Templates to more easily manage the creation of prompts\n",
        "4. Using a Template to create a prompt for a ChatGPT\n",
        "5. Chains\n",
        "   1. Single LLM and Prompot\n",
        "   2. Single LLM (chatGPT) and Prompt\n",
        "   3. Multiple LLMs and Prompts\n",
        "6. Create a vector database using Pinecone\n",
        "   1. Chunk text\n",
        "   2. Create embeddings\n",
        "   3. Create a Pinecone index\n",
        "   4. Query the index for similar text\n",
        "7. Agents\n",
        "   1. Use PythonREPL agent to create and execute Python code to find answer. (notice that the agent has 'memory' of previous answers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import openai\n",
        "import langchain\n",
        "from dotenv import load_dotenv,find_dotenv\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.agents.agent_toolkits import create_python_agent\n",
        "from langchain.tools.python.tool import PythonREPLTool\n",
        "from langchain.python import PythonREPL\n",
        "\n",
        "\n",
        "\n",
        "from tqdm.notebook import tqdm # need this to stop warning\n",
        "\n",
        "import os\n",
        "import pinecone \n",
        "from langchain.vectorstores import Pinecone\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "# load environmnet variables\n",
        "load_dotenv(find_dotenv())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we use the langchain llm wrapper to send a message to the OpenAI API. We ask the question \"explain large language models in one sentence\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C7RnyUOCJWmk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('\\n'\n",
            " '\\n'\n",
            " 'Large language models are deep neural networks that are trained on large '\n",
            " 'amounts of text data and are used to generate predictions for natural '\n",
            " 'language processing tasks.')\n"
          ]
        }
      ],
      "source": [
        "# Run basic query with OpenAI wrapper\n",
        "llm = OpenAI(model_name=\"text-davinci-003\")\n",
        "pprint(llm(\"explain large language models in one sentence\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What's the difference between \"text-davinci-003\" and \"gpt-3.5-turbo\"?\n",
        "\n",
        "| Feature\t| DaVinci\t| Turbo|\n",
        "|-----------|-----------|--------|\n",
        "|Model Size | 175B parameters | 6B parameters|\n",
        "|Performance\t| Higher accuracy and ability to generate longer texts | Lower accuracy and limited ability to generate longer texts|\n",
        "|Cost| More expensive | Less expensive|\n",
        "|Use Cases | Better suited for complex language tasks such as content creation and language translation\t| Better suited for simple language tasks such as chatbots and basic language processing|\n",
        "|Availability |Only available through OpenAI’s API access program|Available through OpenAI’s API access program and some third-party tools|\n",
        "|Training Data | Trained on a larger and more diverse dataset| Trained on a smaller dataset|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here use GPT-3.5 Turbo because it is cheaper and faster. Also, GPT-3.5 Turbo is more suited for simple language tasks such as chatbots and basic language processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JtHgQ5XpJmgi"
      },
      "outputs": [],
      "source": [
        "# import schema for chat messages and ChatOpenAI in order to query chatmodels GPT-3.5-turbo or GPT-4\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The primary interface through which end users interact with llms is a chat interface. For this reason, some model providers even started providing access to the underlying API in a way that expects chat messages. These messages have a content field (which is usually text) and are associated with a user. Right now the supported users are System, Human, and AI.\n",
        "\n",
        "**SystemChatMessage:**\n",
        "A chat message representing information that should be instructions to the AI system. NOTE: This can also be achieved by include this information in the HumanChatMessage. For instance \"Act like you are Albert Einstein and never leave the role\".\n",
        "\n",
        "**HumanChatMessage:**\n",
        "A chat message representing information coming from a human interacting with the AI system. Typically this is text in the form of a question and/or instructions, but it can also be other information such as images or videos.\n",
        "\n",
        "**AIChatMessage:**\n",
        "A chat message representing information coming from the AI system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yrfYfKfdJyyF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content=\"Sure! Here's an example of a Python script that trains a neural network on simulated data using the Keras library:\\n\\n```python\\nimport numpy as np\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\n\\n# Generate simulated data\\nnp.random.seed(0)\\nX = np.random.rand(1000, 10)\\ny = np.random.randint(2, size=(1000, 1))\\n\\n# Define the neural network model\\nmodel = Sequential()\\nmodel.add(Dense(32, input_dim=10, activation='relu'))\\nmodel.add(Dense(1, activation='sigmoid'))\\n\\n# Compile the model\\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\\n\\n# Train the model\\nmodel.fit(X, y, epochs=10, batch_size=32)\\n\\n# Evaluate the model\\nloss, accuracy = model.evaluate(X, y)\\nprint(f'Loss: {loss}, Accuracy: {accuracy}')\\n```\\n\\nIn this script, we first generate simulated data using `numpy`. We then define a simple neural network model using the `Sequential` class from Keras. The model consists of two dense layers, with the first layer having 32 units and using the ReLU activation function, and the second layer having 1 unit and using the sigmoid activation function.\\n\\nAfter defining the model, we compile it using the binary cross-entropy loss function and the Adam optimizer. We then train the model on the simulated data for 10 epochs with a batch size of 32.\\n\\nFinally, we evaluate the trained model on the same simulated data and print the loss and accuracy.\", additional_kwargs={}, example=False)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0.3)\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are an expert data scientist\"),\n",
        "    HumanMessage(content=\"Write a Python script that trains a neural network on simulated data \")\n",
        "]\n",
        "response = chat(messages) # note that this returns back an AIMessage\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(\"Sure! Here's an example of a Python script that trains a neural network on \"\n",
            " 'simulated data using the Keras library:\\n'\n",
            " '\\n'\n",
            " '```python\\n'\n",
            " 'import numpy as np\\n'\n",
            " 'from keras.models import Sequential\\n'\n",
            " 'from keras.layers import Dense\\n'\n",
            " '\\n'\n",
            " '# Generate simulated data\\n'\n",
            " 'np.random.seed(0)\\n'\n",
            " 'X = np.random.rand(1000, 10)\\n'\n",
            " 'y = np.random.randint(2, size=(1000, 1))\\n'\n",
            " '\\n'\n",
            " '# Define the neural network model\\n'\n",
            " 'model = Sequential()\\n'\n",
            " \"model.add(Dense(32, input_dim=10, activation='relu'))\\n\"\n",
            " \"model.add(Dense(1, activation='sigmoid'))\\n\"\n",
            " '\\n'\n",
            " '# Compile the model\\n'\n",
            " \"model.compile(loss='binary_crossentropy', optimizer='adam', \"\n",
            " \"metrics=['accuracy'])\\n\"\n",
            " '\\n'\n",
            " '# Train the model\\n'\n",
            " 'model.fit(X, y, epochs=10, batch_size=32)\\n'\n",
            " '\\n'\n",
            " '# Evaluate the model\\n'\n",
            " 'loss, accuracy = model.evaluate(X, y)\\n'\n",
            " \"print(f'Loss: {loss}, Accuracy: {accuracy}')\\n\"\n",
            " '```\\n'\n",
            " '\\n'\n",
            " 'In this script, we first generate simulated data using `numpy`. We then '\n",
            " 'define a simple neural network model using the `Sequential` class from '\n",
            " 'Keras. The model consists of two dense layers, with the first layer having '\n",
            " '32 units and using the ReLU activation function, and the second layer having '\n",
            " '1 unit and using the sigmoid activation function.\\n'\n",
            " '\\n'\n",
            " 'After defining the model, we compile it using the binary cross-entropy loss '\n",
            " 'function and the Adam optimizer. We then train the model on the simulated '\n",
            " 'data for 10 epochs with a batch size of 32.\\n'\n",
            " '\\n'\n",
            " 'Finally, we evaluate the trained model on the same simulated data and print '\n",
            " 'the loss and accuracy.')\n"
          ]
        }
      ],
      "source": [
        "# here we extract the 'content' from the AIMessage object\n",
        "pprint(response.content, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Templating\n",
        "\n",
        "The templating system is a way to provide a template for the AI to fill in. The template is a string with a special syntax that indicates where the AI should fill in information. See https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/ for more information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2grf7I8AJ_hK"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"\n",
        "You are an expert data scientist with an expertise in building deep learning models. \n",
        "Explain the concept of {concept} in a couple of lines\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"concept\"],\n",
        "    template=template,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vcz7Q9Y-KFvI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nAn autoencoder is an unsupervised deep learning model that learns to reconstruct its input. It consists of two main components: an encoder that compresses the input data into a latent representation, and a decoder that reconstructs the input data from the latent representation. Autoencoders are mainly used for dimensionality reduction, denoising, and feature learning.'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run LLM with PromptTemplate\n",
        "llm(prompt.format(concept=\"autoencoder\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Chains\n",
        "\n",
        "The LangChain is a way to chain together multiple llms. The output of one llm is used as the input to the next llm. This is useful for a number of reasons. For instance, it allows you to use a more general llm to generate a prompt for a more specific llm. It also allows you to use multiple llms to generate a single answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dm78i-rUKXIB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('\\n'\n",
            " 'An autoencoder is a type of artificial neural network used to learn '\n",
            " 'efficient data codings in an unsupervised manner by learning to reconstruct '\n",
            " 'its own inputs. It consists of two parts: an encoder which maps the input '\n",
            " 'data into a lower-dimensional representation, and a decoder which '\n",
            " 'reconstructs the original input from the compressed representation.')\n"
          ]
        }
      ],
      "source": [
        "# Define chain with language model and prompt as arguments.\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt) # one llm and one prompt\n",
        "\n",
        "# Run the chain only specifying the input variable.\n",
        "pprint(chain.run(\"autoencoder\")) # we save a few lines of code by taking this approach instead of the previous one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "B6MF4-nMKul3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('\\n'\n",
            " '\\n'\n",
            " 'An autoencoder is a type of artificial intelligence program that can learn '\n",
            " \"to copy its own input. It's like a copy machine that can take a picture of \"\n",
            " \"something and then make a copy of it. But it's not just a copy machine. It's \"\n",
            " 'like a smart copy machine that can make a better copy of the original.\\n'\n",
            " '\\n'\n",
            " 'The autoencoder works by taking the input it is given and breaking it down '\n",
            " 'into smaller parts. These parts are called “features.\" The autoencoder looks '\n",
            " 'at each feature and tries to figure out how to best represent it in a '\n",
            " 'simpler form. This simpler form is called an “encoding”. This encoding is '\n",
            " 'like a language that the autoencoder can understand.\\n'\n",
            " '\\n'\n",
            " 'Once the autoencoder has made a simplified version of the input, it uses '\n",
            " 'that encoding to make a new version of the input. This new version is called '\n",
            " 'the “reconstruction”. This reconstruction is like the autoencoder’s best '\n",
            " 'guess at what the original input was.\\n'\n",
            " '\\n'\n",
            " 'The autoencoder is constantly trying to improve its encoding so that it can '\n",
            " 'create better reconstructions. It does this by comparing the reconstruction '\n",
            " 'with the original input. If the reconstruction')\n"
          ]
        }
      ],
      "source": [
        "# Define a second prompt \n",
        "\n",
        "second_prompt = PromptTemplate(\n",
        "    input_variables=[\"ml_concept\"],\n",
        "    template=\"Use the concept description of {ml_concept} and explain it to me like I'm five. Use about 500 words to describe this.\",\n",
        ")\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt) # create another chain with a new prompt\n",
        "\n",
        "# Run the chain only specifying the input variable.\n",
        "pprint(chain_two.run(\"autoencoder\")) # we save a few lines of code by taking this approach instead of the previous one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SkJKFyk1K-MO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "Autoencoders are neural networks that are trained to encode data into a lower-dimensional representation and then reconstruct the original input data from the encoded representation. Autoencoders can be used for dimensionality reduction, anomaly detection, and data denoising.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m\n",
            "\n",
            "Autoencoders are like robots that help you learn things. They help you learn things by taking a lot of complex information and breaking it down into simpler pieces. It's like taking a puzzle and breaking it into smaller pieces that are easier to understand.\n",
            "\n",
            "Autoencoders can help you reduce the amount of data you have to work with, which can make it easier to analyze and understand. For example, if you had a really big dataset of numbers and wanted to understand it better, an autoencoder could help you break it down into smaller, more manageable pieces. \n",
            "\n",
            "Autoencoders can also help you identify anomalies in your data, which means they can help you identify data that looks strange or out of place. For example, if you have a dataset of numbers and one of them looks really different from the rest, an autoencoder can help you detect that. \n",
            "\n",
            "Finally, autoencoders can help you clean up data that has been corrupted. For example, if you have a set of numbers that has been corrupted, an autoencoder can help you remove the bad parts and make the data more accurate. \n",
            "\n",
            "To use an autoencoder, you first need to give it\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "('\\n'\n",
            " '\\n'\n",
            " 'Autoencoders are like robots that help you learn things. They help you learn '\n",
            " 'things by taking a lot of complex information and breaking it down into '\n",
            " \"simpler pieces. It's like taking a puzzle and breaking it into smaller \"\n",
            " 'pieces that are easier to understand.\\n'\n",
            " '\\n'\n",
            " 'Autoencoders can help you reduce the amount of data you have to work with, '\n",
            " 'which can make it easier to analyze and understand. For example, if you had '\n",
            " 'a really big dataset of numbers and wanted to understand it better, an '\n",
            " 'autoencoder could help you break it down into smaller, more manageable '\n",
            " 'pieces. \\n'\n",
            " '\\n'\n",
            " 'Autoencoders can also help you identify anomalies in your data, which means '\n",
            " 'they can help you identify data that looks strange or out of place. For '\n",
            " 'example, if you have a dataset of numbers and one of them looks really '\n",
            " 'different from the rest, an autoencoder can help you detect that. \\n'\n",
            " '\\n'\n",
            " 'Finally, autoencoders can help you clean up data that has been corrupted. '\n",
            " 'For example, if you have a set of numbers that has been corrupted, an '\n",
            " 'autoencoder can help you remove the bad parts and make the data more '\n",
            " 'accurate. \\n'\n",
            " '\\n'\n",
            " 'To use an autoencoder, you first need to give it')\n"
          ]
        }
      ],
      "source": [
        "# Define a sequential chain using the two chains above: the second chain takes the output of the first chain as input\n",
        "\n",
        "overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True) # previously we only used llm chain, now we use two chains\n",
        "\n",
        "# Run the chain specifying only the input variable for the first chain.\n",
        "explanation = overall_chain.run(\"autoencoder\")\n",
        "pprint(explanation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a Knowledge Base using Pinecone and LangChain\n",
        "\n",
        "We will use Pinecone to create a vector database. We will use the LangChain to create a knowledge base. The knowledge base will be used to answer questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mDDu1B_SLQls"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(page_content='Autoencoders are like robots that help you learn things. They help you learn things by taking a lot', metadata={}), Document(page_content=\"of complex information and breaking it down into simpler pieces. It's like taking a puzzle and\", metadata={}), Document(page_content='breaking it into smaller pieces that are easier to understand.', metadata={}), Document(page_content='Autoencoders can help you reduce the amount of data you have to work with, which can make it easier', metadata={}), Document(page_content='to analyze and understand. For example, if you had a really big dataset of numbers and wanted to', metadata={}), Document(page_content='understand it better, an autoencoder could help you break it down into smaller, more manageable', metadata={}), Document(page_content='pieces.', metadata={}), Document(page_content='Autoencoders can also help you identify anomalies in your data, which means they can help you', metadata={}), Document(page_content='identify data that looks strange or out of place. For example, if you have a dataset of numbers and', metadata={}), Document(page_content='one of them looks really different from the rest, an autoencoder can help you detect that.', metadata={}), Document(page_content='Finally, autoencoders can help you clean up data that has been corrupted. For example, if you have', metadata={}), Document(page_content='a set of numbers that has been corrupted, an autoencoder can help you remove the bad parts and make', metadata={}), Document(page_content='the data more accurate.', metadata={}), Document(page_content='To use an autoencoder, you first need to give it', metadata={})]\n"
          ]
        }
      ],
      "source": [
        "# Import utility for splitting up texts and split up the explanation given above into document chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 100,\n",
        "    chunk_overlap  = 0,\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents([explanation])\n",
        "print(texts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "F6lfAdeuLhtp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Autoencoders are like robots that help you learn things. They help you learn '\n",
            " 'things by taking a lot')\n"
          ]
        }
      ],
      "source": [
        "# Individual text chunks can be accessed with \"page_content\"\n",
        "\n",
        "pprint(texts[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Z5sv4e3tLw2y"
      },
      "outputs": [],
      "source": [
        "# Instantiate OpenAI embeddings\n",
        "\n",
        "# note, there are a few approaches that seem to achieve the same thing\n",
        "# unlear if there is a difference between them; but the last one seems to be the most recent\n",
        "# and doesn't generate any warnings.\n",
        "#embeddings = OpenAIEmbeddings(model_name=\"ada\")\n",
        "#embeddings = OpenAIEmbeddings(engine=\"text-embedding-ada-002\")\n",
        "embeddings = OpenAIEmbeddings(deployment=\"text-embedding-ada-002\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dqzoir4hMlfl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.03675442777659658, -0.014334758655346952, 0.00732694981868598, -0.024613765584562814, -0.0024101810084608036, 0.015571431241262477, 0.003339347160298931, -0.02676796698040097, -0.0287758985693582, -0.028536541203024842, 0.011402648612893269, 0.01772563449974589, 0.005219288477283526, -0.008570271116852697, 0.0007243009011607405, -0.006273119147984753, 0.016316094463976794, 0.02511907144094377, -0.012725755389396895, -0.006060358493301414, -0.015371968011081517, 0.02922801472772964, -0.019839943622076906, -0.023603150146510377, 0.013802857018638603, -0.011562219569567088, 0.00743333014602765, -0.0445733878898064, 0.010797610210099201, -0.016515557694157756, 0.031594978640896394, -0.006176711889019869, 0.004388191529642423, -0.03773844464035374, -0.020518119722279324, -0.022885083635446078, 0.014707090266704111, -0.011422595680969469, 0.012486398954386167, -0.009122118890314616, 0.012353423778039737, 0.005338966229127576, 0.00567805381356747, -0.008284373696083638, -0.002807445290759925, 0.017486277133412532, -0.007958584001807439, -0.021116509412822202, -0.009527694062927725, 0.021010128154157905, 0.03872246522940141, 0.008317617257339588, -0.010119435041219413, 0.0039061552348179994, 0.001130291792912542, 0.002403532063378956, -0.005904112358414504, 0.0114691366667278, 0.01823094035612685, -0.014281568957337431, -0.0013172885712071914, -0.004368244927227538, -0.017020863550538712, 0.017672442939091114, 0.00751976433661575, 0.001741979024373129, -0.01845699843531257, 0.012406614407371886, 0.010551605994159911, 0.0023486797216453236, 0.008390754023425307, 0.017592658392076833, -0.012739052813899275, 0.0007741667087059805, 0.010764366648843251, -0.02244626490157702, 0.004866903468341252, 0.004813712839009102, -0.0009316595935553168, -0.0028822440020777845, 0.008576919829103887, -0.02517226113895329, -0.023470175901486576, 0.008876114674375326, 0.0071274865885050205, 0.004241918463132299, -3.617868636810494e-05, 0.008776383059284847, -0.00740673529702289, -0.001214232483575788, 0.005076339766898997, -0.01122313245078851, 0.014481032187518391, -0.005644809786650205, 0.012373369914793307, 0.008330914681841968, 0.0032612240928554764, 0.01779212162225779, 0.007260462230512766, -0.019720266801555485, -0.016887887442869655, 0.01441454413368386, -0.038163969675010935, -0.020837259772981703, -0.02922801472772964, 0.011974443454431388, 0.0008273569305844796, 0.0034540386107852457, 0.014547519310030291, -0.00026179551871634147, 0.0027442818258816477, 0.05114237519863042, 0.0010771015128263784, -0.049706242176501825, 0.008670002731943176, -0.02296486818246036, 0.007021106261163351, 0.019175066809022128, -0.0006461778337172857, -0.008124802739409819, 0.01929474549218881, -0.0023320577081866914, 0.0313822161235678, 0.00020933252884414833, 0.022725512678772257, 0.00043258591537955447, -0.008025071124319338, 0.0030800450541959468, -0.012705809252643325, -0.01565121578827676, 0.017180434507212534, 0.02195425460705318, 0.01932134034119357, 0.012785593799657605, -0.020611201693795985, 0.02991948638978918, 0.020371846190107887, 0.007140784478668716, -0.024813228814743772, -0.020278764218591226, 0.014321461230844571, 0.00760619852720385, -0.027685498584291486, -0.00797188142630982, -0.02603660304483429, -0.010106137616717033, 0.011376053763888509, 0.040796882078225294, 0.0008327590674962359, 0.0010687906225123908, 0.008556973692350317, -0.031142862482524954, -0.005325668804625196, 0.01812456096010781, 0.028323780548341504, 0.015624620939271998, 0.004594303472074572, 0.0058243268800775945, -0.02171489910336508, 0.008244480491253868, 0.010697878595008722, 0.004059077013579314, -0.00554175381543413, -0.005086312835275782, 0.01099707344028016, 0.02620947142601049, 0.027313166972934327, 0.0073136523941836, 0.0036767725666760277, -0.015757597046941057, -0.002057795766687872, 0.02917482502972012, -0.020238870082438826, 0.024733442405084235, -0.000988174171559411, 0.02632914824653191, 0.014534221885527911, -0.011395999900642079, -0.013922534770482652, -0.010405332461988472, 0.015571431241262477, 0.026502016627708107, 0.025744055980491412, 0.002764228195465875, -0.0112962682855516, -0.010033001781953942, 0.019441017161714987, -0.0014718725280313035, -0.013603393788457643, 0.007180676752175856, 0.019720266801555485, 0.012792242511908795, -0.008291022408334828, -0.013118033137507625, -0.6497714901630716, 0.007080945137085376, -0.005245883326288286, -0.021236186233343623, 0.014161890274170752, -0.01736660031289111, -0.016542152543162516, -0.004637520567368623, -0.02214042041273176, 0.012439857968627836, 0.0005044758150875186, 0.0032911435308164887, -0.012193852821365918, -0.009627425678018204, 0.0011078521562341182, -0.021568625571193642, 0.03140881097257256, -0.053004033255416215, -0.008836221469545557, 0.01876284292415783, -0.0075663057880353945, 0.02888227796537724, -0.020797367499474563, 0.009015738562972947, -0.006967916097492516, 0.03372258518772979, -0.0008269413860687802, 0.0017220326547889016, 0.002115972697377757, -0.0054852392956377, -0.02229999136940558, 0.010192571807305133, -0.0060503849592633135, 0.0020095921372054295, 0.032578995504653555, 0.004700683799416242, 0.004271837668262653, 0.043084061444377764, 0.014188486054498142, 0.04430743567446828, -0.02167500682985794, -0.03430767931641555, 0.020571309420288845, -0.013922534770482652, -0.0073535451333520555, -0.0032396155452084512, -0.009747104361184884, 0.015345372230754129, -0.00276090383934028, -0.02178138622587698, 0.007732525456960404, 0.010112786328968223, -0.0035471215136245356, -0.008849519825370565, 0.00738678916026932, -0.005102934615903756, 0.02171489910336508, -0.023762721103184198, 0.02207393329021986, -0.020983533305153144, 0.030079057346463, 0.02509247659193901, -0.02268562040526512, 0.00010960089920175252, -0.01460070993936244, 0.004122240245626934, -0.016781508046850614, -0.00045419443392274723, -0.021116509412822202, -0.020877153909134104, 0.03358961094270599, 0.020411738463615024, 0.01125637601204446, 0.0142150809035029, 0.01109015634311945, 0.017645848090086354, 0.02606319789383905, -0.020066003563907885, -0.014015617673321943, 0.027339761821939087, 0.027738688282301006, 0.004162132984795389, -0.027220085001417666, -0.015903868716467238, 0.005704648662572229, 0.008783031771536037, -0.01835061903929353, -0.017406492586398252, -0.01083750341492897, -0.01124307858754208, 0.002672807470689383, 0.008138100163912199, -0.014454436407191, -0.04765842017668271, 0.008769734347033657, 0.01105026406961231, -0.008656705307440796, 0.004251891531509084, 0.012878676702496896, -0.024002076606872296, -0.007745822881462784, -0.026874348239065267, 0.01144919052997423, 0.017619253241081594, 0.008583568541355077, 0.007958584001807439, 0.01133616149038137, 0.018004882276941133, 0.01566451321277914, -0.005345614941378766, -0.005874192687622834, -0.008590217253606267, -0.00034345077275090534, 0.01819104808261971, -0.003262886270918274, -0.03132902642555828, -0.013749666389306452, 0.030557770216484457, 0.01122313245078851, -0.035132127086144146, 0.03696719029392518, -0.0003066747338655245, 0.003972642822991214, 0.008151398519737207, -0.00370004329238585, 0.0002010215512186643, -0.02671477728239145, -0.02337709206732466, -0.02168830425436032, -0.0023187602836843113, -0.008031719836570528, -0.028403566958001045, -0.00574121704561509, -0.013842749292145743, 0.023084546865627036, 0.00552180767868056, 0.05100940095360662, -0.03039819925981064, 0.01924155393153403, -0.01828413191678163, -0.0032545753806042864, 0.0074466280361913445, 0.02244626490157702, 0.0008086572527550147, -0.0068016968942288215, -0.0013447147420740076, -0.003942723617860859, -0.005761163648029974, 0.011535624720562328, 2.5569215407232157e-05, -0.011010370864782541, -0.012173906684612348, -0.031568383791891634, 0.010445225666818242, 0.011535624720562328, -0.017512873845062553, -0.008703246293199126, -0.017526171269564933, -0.02215371783723414, -0.02598341334682477, 0.013450471544035014, 0.013078139932677854, 0.002300476092162881, 0.015877273867462478, -0.009773699210189644, -0.01460070993936244, 0.02291167848445084, 0.041381976206911045, -0.024374408218229456, -0.0036202580468795978, 0.00282905383840695, -0.02340368691632942, 0.0020212276164756696, 0.02255264429759606, -0.008523729199771736, 0.030265223152141578, -0.01566451321277914, -0.013816154443140983, 0.01517250478090056, -0.015278885108242228, 0.0226989178297675, 0.026954132786079547, -0.010458523091320622, -0.0007633624930901323, 0.021169699110831722, 0.008244480491253868, 0.024893013361758053, 0.011010370864782541, -0.021542030722188882, 0.023190926261646077, -0.005674729457441875, 0.016169820931805357, -0.009880079537531313, 0.02707381146924623, 0.01437465186017672, -0.008264427559330068, -0.008291022408334828, 0.006642125937555002, 0.01127632214879803, 0.008423997584681257, 0.005784434140909139, -0.016901186730017295, -0.0031299108617411863, 0.006329633667781183, 0.02511907144094377, -0.006981213521994896, 0.014520924461025531, -0.03329706387836311, 0.02144894875067222, -0.005438697844218055, -0.00781895918188719, -0.034094916799086945, 0.0033526448176319683, 0.013137979274261195, -0.008257778847078878, 0.027818474691960544, -0.0007538048528137179, 0.031116265770874937, -0.01843040358630781, 0.002069431245958112, -0.00555505123993651, -0.021196293959836483, 0.031089670921870177, 0.004029157808448959, 0.005817678167826404, 0.02208723071472224, 0.010006406001626554, 0.011994389591184958, -0.004142186848041819, -0.038137374826006175, 0.013477066393039774, 0.020212275233434066, -0.008264427559330068, 0.009966513728119413, 0.00710754045175145, -0.002883906180140582, 0.012167257972361158, -0.005328993160750791, 0.039280960783791896, 0.0023121115714331212, -0.012685862184567126, 0.019640480391895948, 0.00762614466395742, -0.006725235772017507, 0.02599671077132715, 0.014135295425165992, 0.01494644577039221, -0.014108700576161232, -0.030743936022163035, 0.02295157075795798, -0.010578200843164671, 0.024627063009065194, -0.010212517944058702, -0.0043117304074311085, -0.012094121206275437, -0.005807705099449619, 0.019919730031736447, 0.01865646166549353, 0.04630206797627787, 0.017978287427936373, 0.014707090266704111, 0.013144627986512385, -0.009354826613074154, -0.011642005047903999, -0.012386667339295688, -0.013882642496975512, 0.0017685741062085465, -0.0058210025239519994, -0.002877257235058735, 0.007041052863578236, -0.028509946354020082, -0.0059440046319216445, -0.00543537348809246, -0.009447909515913445, 0.02603660304483429, -0.0026212794850813455, -0.0012242056683679017, 0.017898502880922092, 0.005019825247102566, 0.031169457331529715, -0.021635112693705542, -0.023230820397798477, 0.019986217154248347, 0.01087074697618492, 0.002952056179207252, -0.03356301609370123, -0.024786632103093755, -0.0026246038412069406, -0.01771233707524351, -0.017207029356217294, -0.0299460831014392, 0.020930343607143624, -0.011648653760155189, -0.012360072490290927, -0.04531805111252072, 0.0035670676503781053, 0.04289789750134444, -0.00784555403089195, -0.0020777421362720996, -0.013231062177100484, -0.009501099213922965, -0.00749981819986218, -0.00721392077909312, -0.00752641304886694, 0.024374408218229456, 0.013842749292145743, -0.009720508580857493, 0.004966635083431732, -0.006023790110258553, -0.01839051131280067, 0.0023885724608137785, 0.010624742760245632, -0.0004438057337187663, 0.013776261238311212, -0.010498415364827762, 0.003003584164815289, 0.005688026881944254, 0.012792242511908795, 0.006678694320597862, 0.029786512144765378, 0.006309687531027613, -0.01820434550712209, -0.008191290793244347, 0.039254365934787136, 0.058030508146092605, 0.008789680483787227, -0.03305771023732027, -0.008696597580947936, -0.03470660577677746, -0.001966375274742037, -0.04366915557306352, -0.023549960448500856, 0.006193333669647844, 0.005023149603228161, -0.014108700576161232, 0.013284251875110004, 0.016143226082800596, -0.008876114674375326, 0.013842749292145743, -0.010538308569657531, -0.001127798409403017, -0.021276080369496023, -0.015598026090267237, -0.04053093358817769, -0.005325668804625196, 0.024228136548703275, 0.0034540386107852457, 0.005089637191401377, 0.04364255699876824, -0.015611323514769617, 0.01817775065811733, 0.04029157622184433, -0.015810786744950577, -0.02674137213139621, 0.01926815064318405, 0.02579724754114619, 0.01518580220540294, 0.027286572123929567, -0.019547398420379287, 0.020105895837415025, 0.0004367413896403804, 0.027978045648634365, -0.0018383862833380139, 0.005724595264987115, 0.011442541817723039, 0.023696233980672297, -0.004913444454099582, -0.00729370625743003, 0.0009399705420769687, -0.016542152543162516, 0.004926742344263276, 0.011648653760155189, 0.003922777015445975, -0.017153839658207774, 0.01104361535736112, -0.01877614034866021, -0.03656826383356326, -0.0019514154393462022, -0.00381307233197871, -0.027206787576915286, 0.024733442405084235, -0.003216344819498629, -0.008856168537621755, -0.019148471960017368, -0.022113825563727, -0.03047798380682492, 0.013895939921477892, -0.024972797908772333, -0.012838784428989756, -0.006814994318731202, -0.024241433973205655, -0.01876284292415783, -0.024733442405084235, 0.0013945805496192475, -0.013842749292145743, -0.03614273879890607, -0.030797125720172555, 0.001031391266853461, -0.009654021458345595, 0.003889533221359367, -0.00015988226581460784, -0.00722056949134431, -0.01074442051208968, 0.0032279802987688687, -0.00785220274314314, -0.006266470435733563, 0.002386910282750981, -0.03672783292759182, -0.017938395154429233, 0.0221803126862389, -0.01884262747117211, -0.018018179701443513, -0.005049744452232921, 0.002192433586758414, 0.027339761821939087, -0.015797489320448197, 0.02208723071472224, -0.0020744177801465045, 0.01442784155818624, -0.00092667300115926, 0.04124899823659673, 0.006226577696565108, -0.0009416327201397663, -0.03712675938795374, 0.007739174169211594, -0.012180555396863538, -0.004793766702255532, 0.0025531294860146755, 0.010425279530064672, 0.00391945265932038, 0.03664804838057754, -0.0013505323652937989, 0.004810388482883507, -0.010804258922350391, 0.007100891739500261, 0.014028915097824323, -0.0015333736984314546, -0.020145788110922165, 0.006888130619155606, 0.02986629669177966, -0.004903471385722797, -0.011382702476139699, -0.001170184415665668, 0.0006490866453271813, -0.002277205366453059, -0.0437489401200778, 0.023603150146510377, -0.016063439673141056, -0.017393195161895872, -0.009554289843255114, -0.007752471593713974, -0.01825753520513161, -0.01144919052997423, 0.021648411980853183, -0.017273516478729194, 0.02247285975058178, 0.0002422647373035617, -0.02144894875067222, -0.042498971040982526, -0.015837381593955337, -0.02885568311637248, 0.01933463776569595, 0.00013619599558908603, 0.0012408275654112054, -0.004534464596152548, 0.023470175901486576, -0.006266470435733563, -0.02505258431843187, 0.010046299206456322, -0.050504095097225664, -0.0009998095344143222, 0.001956401973534595, 0.002990286507482252, 0.03523850648216319, 0.0014751968841568985, 0.020425035888117404, -0.0013920872825250513, -0.015850679018457717, -0.0009707211272770443, -0.01570440548628628, -0.023270712671305618, 0.01876284292415783, 0.02289838105994846, 0.03648847556125846, 0.05973259338355932, -0.019826646197574526, 0.028722707008703423, 0.00753306176111813, -0.006186684957396654, 0.0013039910302894827, 0.007652739978623494, -0.01119653667046112, -0.02986629669177966, 0.010079542767712273, 0.026861050814562887, 0.004045779589076934, 0.003289481352753691, -0.023430283627979435, 0.03757887554632518, 0.01730011319037921, 0.007752471593713974, -0.019600588118388808, -0.0003615271338068212, -0.03132902642555828, -0.017406492586398252, 0.03967988724415381, 0.015558132885437469, 0.020411738463615024, 0.003372591187216196, -0.0033875507897813736, 0.023696233980672297, 0.0028190805371995074, 0.01525228932791484, 0.0007454939042920661, 0.020012812003253107, -0.005309046558335906, 0.01123642987529089, 0.0055051854323912705, -0.0009757077196731011, -0.008570271116852697, 0.010604795692169431, -0.03366939548972027, -0.008297671120586018, 0.02192765975804842, 0.016475663558005355, 0.010538308569657531, 0.013011652810165955, -0.01865646166549353, -0.0018732923719027475, -0.024095160441034214, -0.01874954549965545, -0.020903748758138864, -0.026488719203205727, 0.0007592069897254742, 0.0022157043124682364, -0.012067526357270677, -0.004923417988137681, -0.03529169618017271, -0.0029736644940236193, 0.017007566126036336, -0.00537221025604484, 0.03686080717261562, -0.020863856484631724, -0.019374530039203086, 0.0017768851129378626, 0.01809796611110305, 0.039307555632796656, 0.01111010247987302, 0.008922655660133656, 0.04773820472369699, 0.008397402735676497, -0.01097712730352659, 0.03526510133116795, 0.017512873845062553, 0.010458523091320622, 0.013935832194985032, 0.02231328879390796, -0.03319068448234407, -0.015438455133593418, 0.030610959914493977, -0.019946324880741207, 0.015890571291964858, -0.04694035180297315, 0.007180676752175856, -0.020451632599767424, 0.0016638559569296743, -0.016196415780810117, 0.001733668017643813, -0.006834940455484772, 0.005013176069190062, -0.008450593365008648, 0.02215371783723414, -0.0023852481046881834, -0.010033001781953942, -0.04345639305573492, 0.010212517944058702, -0.015478348338423188, -0.0008967535049905832, -0.016302797039474414, -0.0009399705420769687, 0.002840689084846532, -0.013423876695030253, -0.011954497317677818, 0.009986459864872984, -0.00282905383840695, 0.01900219842784593, 0.024467492052391373, 0.03268537862596311, 0.009880079537531313, 0.011834819565833769, -0.00011084754730076674, -0.006140143505977008, -0.016289497752326777, 0.029068443771055823, -0.037445901301301376, -0.011362756339386128, -0.004228621038629919, 0.011382702476139699, -0.010478469228074192, -0.0019530776174089997, -0.005688026881944254, -0.008324265969590778, -0.003307765544275121, -0.009760401785687264, -0.00040557525992460547, -0.01442784155818624, 7.796727462985776e-05, 0.006273119147984753, -0.009414665023334864, -0.013516959597869544, 0.00562153929377104, 0.016369284161986315, 0.02711370374275337, -0.05433378688152578, -0.01104361535736112, -0.0007118344492744305, 0.00279248545536409, 0.017951692578931613, 0.026382339807186687, -0.017060755824045853, -0.004860254290428747, 0.03050457865582968, -0.014494329612020771, 0.01499963639972436, -0.010265708573390852, 0.027871664389970064, -0.008656705307440796, 0.015797489320448197, -0.015531538036432709, -0.016741615773343474, 0.020544714571284085, -0.0292546095767344, -0.008929304372384846, -0.0031930740937888063, -0.01105026406961231, 0.012114068274351637, -0.0012192191341795092, -0.013410579270527873, 0.003329374091922146, 0.015332074806251749, 0.012406614407371886, -0.007100891739500261, -0.009534343706501544, 0.016169820931805357, 0.03279175802198215, 0.007253813518261576, 0.030690744461508258, -0.016808102895855374, -0.02562437915996999, -0.013264305738356434, 0.013616691212960023, 0.006289740928612728, -0.0297333205841106, 0.002721011100171825, -0.016715020924338714, 0.01440124670918148, -0.046461640795596955, -0.0023520040777709186, 0.004168781697046579, -0.012699160540392135, -0.024068565592029453, 0.0036800969228016228, 0.037445901301301376, -0.015265587683739848, 0.011768331511999238, 0.008530377912022926, 0.029041848922051063, -0.011568868281818278, -0.030664149612503497, -0.013736368964804072, -0.0044181107347727785, 0.021089914563817442, -0.02191436233354604, 0.012286935724205207, -0.02590362693716523, 0.006585611417758572, -0.01808466868660067, -0.031036481223860657, -0.0023353822971429435, 0.006901428509319301, -0.04497231435016832, -0.011003722152531351, -0.0021824602855509715, 0.0032080339291846414, 0.017113947384700633, 0.021608517844700782, -0.0011469136899558456, 0.006848238345648466, -0.009228499217656285, 0.009075577904556285, -0.020305359067595986, 0.00729370625743003, -0.01085080083943135, 0.003969318466865619, -0.023549960448500856, -0.02589032951266285, -0.04848286794641131, -0.025704163706984272, 0.014547519310030291, -0.009853484688526553, -0.03382896830903935, 0.03260559407894883, 0.012978408317587375, -0.008503783063018168, 0.0034640116791620308, -0.0024450869806102084, 0.01772563449974589, -0.030531175367479697, 0.028962064375036782, -0.018031477125945893, -0.020425035888117404, 0.024640360433567574, -0.005887490112125214, -0.02549140305230093, -0.011761682799748048, 0.028323780548341504, 0.013776261238311212, 0.005897463180501999, -0.01768574222623875, 0.017207029356217294, 0.014068807371331463, 0.0007562981199079142, 0.004258540243760273, 0.025704163706984272, -0.01856337969397687, 0.016488960982507735, 0.002386910282750981, -0.0007521426747509204, -0.00758625239045028, -0.019773456499565006, 0.003199723038870654, 0.006967916097492516, -0.00728705754517884, -0.006781750291813937, 0.010106137616717033, 0.004853605578177557, 0.015465050913920808, -0.03265878377695835, 0.0011809886894891806, -0.009142065958390814, 0.012466452817632596, -0.021036723003162665, 0.02151543587318412, -0.0046242231428662425, -0.036036359402887026, 0.006612206732424647, -0.001145251511893048, -0.0026611722242498004, -0.0217680888013746, -0.017007566126036336, 0.005152800423448996, -0.03656826383356326, -0.010425279530064672, 0.0015325426094000558, -0.007759120305965164, -0.0378448277616633, 0.0029985973977962395, 0.0011809886894891806, -0.013310847655437394, -0.004554410732906118, 0.1724426251735301, -0.016382581586488695, 0.0019497532612834047, 0.0346800109277727, 0.0008003463042333629, -0.01525228932791484, 0.011848116990336149, 0.0040756992598686035, -0.026914240512572407, -0.014268270601512421, 0.008975846289465806, 0.0018982252756753674, -0.024121755290038974, 0.002356990611959311, 0.0054852392956377, -0.002260583585825084, -0.026502016627708107, -0.015731002197936297, 0.007260462230512766, 0.008809626620540797, 0.006116873013097843, 0.014121998000663612, -0.006828291743233582, -0.0292546095767344, 0.01932134034119357, 0.007872149811219338, -0.031009886374855897, 0.00038936887829316895, 0.02517226113895329, 0.010106137616717033, -0.02247285975058178, -0.0032346290110200587, 0.009487801789420585, 0.015278885108242228, -0.038323538769039496, 0.014055509946829083, 0.007938636933731239, -0.009115470178063426, 0.025331832095627112, 0.04050433501388241, 0.016316094463976794, 0.004408137666395993, -0.001506778616596037, -0.010411981174239662, 0.0014186823643604688, 0.009394718886581294, -0.016050142248638676, -0.02261913142010796, -0.012333477641286167, 0.009521045350676535, 0.0022855164895977035, 0.011848116990336149, 0.012007687947009967, 0.0297333205841106, 0.006834940455484772, 0.012047580220517107, 0.015092719302563649, 0.006512475117334168, -0.020597904269293605, -0.0003380486358391491, -0.010644688896999202, 0.016382581586488695, 0.005461968802758535, 0.0029420828779998095, 0.0008323435229805365, 0.002930447631560227, -0.005488563651763295, 0.031488599244877354, 0.0032911435308164887, -0.012832135716738566, -0.01084415212718016, -0.007725876279047899, -0.014720387691206491, -0.013197818615844533, -0.014733685115708871, -0.008829572757294367, 0.019520803571374527, 0.0052758029970799555, 0.019454314586217367, -0.012353423778039737, -0.007273759655015146, -0.03361620579171075, -0.002104337218107517, 0.017180434507212534, -0.02566427143347713, -0.023643044282662777, 0.016355986737483934, -0.011376053763888509, -0.02667488500888431, 0.001886589912820456, 0.008364159174420547, -0.015504943187427948, -0.0005634836601858092, 0.008942602728209856, -0.0033659422421343484, 0.001963050685785785, -0.0059440046319216445, 0.0004238593932383711, 0.0010696217115437896, -0.019680374528048345, -0.027765284993951023, 0.0108840444006873, 0.024613765584562814, 0.0214622461751746, 0.003879560152982582, 0.0068050212503544165, -0.01461400736386482, 0.024613765584562814, 0.004700683799416242, -0.012665916047813556, -0.016116631233795836, -0.031515194093882114, 0.02147554359967698, 0.01933463776569595, -0.00380642361972752, 0.009155363382893194, 0.012506346022462367, 0.004065725725830504, 0.03348323154668695, 0.025730758555989032, -0.017379897737393492, -0.023297307520310378, 0.00044339018920306695, -0.0007895420304098504, 0.002217366490531034, -0.003342671516424526, -0.035132127086144146, 0.004723954757956722, -0.014733685115708871, -0.008058315616897918, 0.02561108173546761, -0.01808466868660067, 0.0013821140977329375, 0.01094388374227064, 0.013031598946919526, 0.007951934358233619, -0.004348298790473968, -0.003159830299702199, -0.02585043723915571, 0.014281568957337431, -0.013556851871376684, 0.01112340083569803, 0.009979811152621794, -0.023616449433658017, -0.0222866939449032, -0.01093723503001945, 0.016701723499836334, 0.003116613204408149, -0.0048436325098007715, 0.0004866072262894524, -0.01464060221286958, 0.005488563651763295, -0.008324265969590778, -0.019627182967393568, 0.016528855118660136, -0.0012025971207208768, -0.03662145353157278, -0.013975724468492172, 0.00743333014602765, -0.018058071974950653, -0.04832329512709223, -0.0012915245784031726, 0.022419668189927, -0.007705930142294329, -0.019108579686510228, -0.021036723003162665, -0.1691448340946157, -0.01093058631776826, 0.009840187264024173, -0.034094916799086945, -0.007539710939030634, 0.0015857327730708908, 0.01866975908999591, 0.012725755389396895, -0.02513236886544615, 0.015983655126126775, 0.009348177900822964, -0.008184642080993157, -0.019534100995876907, -0.004394840241893613, 0.02168830425436032, -0.021156401686329342, 0.011369405051637319, 0.02292497590895322, 0.035132127086144146, 0.01446773383169338, 0.028031235346643885, -0.027765284993951023, 0.0107311230875873, 0.0028722707008703423, -0.004115591533375744, 0.0011760020388854593, 0.004354947502725158, 0.03422789476940127, 0.0028722707008703423, -0.035956574855872746, -0.0028573110983051648, 0.0012931867564659701, 0.024095160441034214, 0.012506346022462367, 0.012778945087406415, 0.01781871647126255, -0.009241797573481295, -0.0043117304074311085, -0.0003654748358097975, 0.0063595533385728525, -0.005983897371090099, 0.03236623671261547, -0.014148592849668372, 0.013669880910969543, 0.003392537323969766, 0.024706847556079475, 0.02551799790130569, -0.020943641031646004, 0.0007513115857195217, -0.024972797908772333, 0.01494644577039221, -0.019786753924067386, 0.017260219054226814, 0.0011095143342969157, 0.010212517944058702, 0.006605558020173457, -0.015717704773433917, -0.0010471820748653659, -0.012978408317587375, -0.0024617089940688406, 0.0028373647287209375, 0.0006989524528724213, 0.0004238593932383711, -0.016183118356307737, -0.00027675526680067986, -0.020425035888117404, -0.006309687531027613, -0.016754913197845854, -0.0022539346407432367, 0.009401367598832484, 0.002157527381778352, -0.01444113898268862, -0.012832135716738566, -0.01095718116677302, -0.011781628936501618, 0.009780347922440834, -0.01563791836377438, 0.015624620939271998, 0.024826526239246152, 0.005638161074399015, 0.0017004242235572054, 0.027712093433296246, -0.0039061552348179994, -0.012712457964894515, 0.010631391472496822, 0.003965994110740024, -0.005292424777707931, 0.006106899944721058, 0.0024982771442810434, -0.020198977808931685, 0.022791999801284157, -0.0225260494485913, -0.03441405871243459, 0.011528976008311138, 0.012586130569476646, 0.013171222835517145, -0.017153839658207774, -0.01127632214879803, 0.010192571807305133, -0.01816445323361495, -0.015265587683739848, 0.020956938456148384, -0.023762721103184198, -0.006947969960738946, 0.05537099716858297, -0.009999757289375364, 0.0008190459820628278, 0.0007733356196745817, 0.03263218892795359, -0.038190564524015695, 0.012333477641286167, -0.024294623671215175, 0.005681378169693064, 0.03672783292759182, -0.014879958647880309, 0.03856289613537286, -0.003583689663836738, -0.007958584001807439, 0.013949129619487412, -0.004600952184325762, 0.047498847357363636, 0.005900787536627594, -0.03856289613537286, 0.008084910465902678, -0.00046707643032475654, -0.009029035987475327, -0.09643383146214637, -0.020132490686419785, 0.0061600901083918936, 0.01772563449974589, -0.015411860284588658, 0.03380237346003459, 0.0037266383742212673, 0.01845699843531257, -0.016741615773343474, 0.04279151438003489, -0.013410579270527873, -0.031515194093882114, 0.010358791476230141, -0.017100649960198253, -0.016927781579022055, -0.015717704773433917, -0.0006632152752762888, -0.008523729199771736, -0.023337199793817518, 0.023643044282662777, -0.008783031771536037, 0.015345372230754129, 0.023829210088341355, 0.0004201194634932445, -0.010345494051727761, 0.006655423827718697, -0.02880249341836296, 0.027978045648634365, 0.014028915097824323, -0.019667077103545965, 0.02226009909589844, -0.017512873845062553, 0.001235009942191414, -0.029786512144765378, -0.0010388710681360498, 0.002107661574233112, -0.0006943814049920637, -0.019441017161714987, 0.012406614407371886, 0.003407497159365601, 0.00024081031694669778, 0.009314933408244385, -0.0002777941280899283, 0.001463561637717316, -0.006020465754132958, -0.029839701842774898, -0.016475663558005355, 0.015079421878061269, -0.0030418144930902894, -0.027871664389970064, -0.043296823961706365, -0.039201176236777616, -0.04284470407804441, 0.0030883559445099343, 0.018031477125945893, -0.009986459864872984, 0.020238870082438826, -0.00711418916400264, 0.012346775065788547, 0.008350861749918167, 0.020930343607143624, -0.019201661658026888, -0.011435893105471849, 0.015278885108242228, 0.020704285527957902, -0.011362756339386128, -0.03265878377695835, -0.02920141987872488, 0.0032429399013340463, -0.020677690678953142, -0.003710016360762635, 0.02986629669177966, -0.010099488904465843, 0.030743936022163035, -0.01857667711847925, -0.010338845339476571, -0.004760522675338268, -0.01523899190341246, 0.019573993269384048, -0.003493931117123043, -0.015451752558095798, 0.0016256255122393457, 0.004903471385722797, -0.02506588174293425, -0.016941079003524435, -0.015371968011081517, -0.005561700417849015, 0.006519123829585358, -0.024853121088250912, -0.018004882276941133, -0.005142827355072211, 0.022419668189927, 0.016555449967664896, -0.002380261337669134, -0.01566451321277914, -0.0014494328913528798, -0.014175187698673132, 0.0015192450684823472, 0.006263146079607968, -0.0020212276164756696, -0.014015617673321943, -0.013344091216693344, -0.008184642080993157, 0.017020863550538712, 0.008749788210280086, 0.008563622404601507, 0.03225985731659643, -0.015465050913920808, 0.006994511412158591, 0.001364661111658235, 0.011369405051637319, 0.021036723003162665, -0.016183118356307737, -0.002672807470689383, 0.00272433545629742, -0.002601333115497118, -0.016768210622348234, -0.009554289843255114, -0.0003187256412361351, 0.01122313245078851, 0.007160730615422286, -0.003440740953452208, 0.024720144980581855, 0.016050142248638676, 0.03374918003673455, 0.012366721202542117, -0.0005530949890856603, -0.0014968054318039235, -0.013543554446874304, 0.02510577401644139, -0.014707090266704111, -0.003350982639569171, -0.016249605478819637, -0.036062954251891786, -0.008743138566706266, 0.02632914824653191, 0.0004321703708638551, -0.012765647662904035, 0.0025348455273239033, 0.030079057346463, 0.013324145079939774, 0.05244553770102574, -0.020531417146781705, -0.03140881097257256, -0.00274261964781885, -0.004275162490049563, -0.02224680167139606, 0.003345995872550121, -0.0356374329425251, -0.020398441039112647, 0.0034041728032400058, 0.013018301522417145, 0.0313822161235678, 0.012818838292236186, -0.028988659224041542, -0.013257657026105244, -0.031834336007229756, -0.003372591187216196, -0.012699160540392135, -0.008164695944239587, 0.009786996634692024, -0.014095403151658852, 0.03340344699967267, 0.03324387418035359, 0.014175187698673132, -0.003138221752055174, -0.017858608744769692, 0.0060437362470121235, -0.0011543934912384343, 0.0294939650804225, 0.019121877111012608, -0.03885543947442521, 0.010511712789330142, -0.007466574172944915, 0.03225985731659643, -0.008663354019691986, -0.0022572589968688317, 0.006954618672990136, -0.02148884102417936, 0.011974443454431388, -0.019613885542891188, 0.010312249559149183, -0.017153839658207774, 0.0014195134533918675, -0.006632152869178217, 0.0009740455416103036, 0.02663499273537717, 0.007473222885196105, 0.001569110876027587, -0.008450593365008648, 0.05005197893885423, -0.0006993679973881207, -0.022871786210943698, 0.02175479137687222, 9.962773623751293e-05, -0.0069080772215704914, -0.009707211156355113, 0.01098377601577778, -0.017632550665583974, 0.0034041728032400058, 0.002770876907717065, 0.006439338351248448, 0.027818474691960544, 0.007174028039924666, 0.003209696107247439, 0.0034008484471144108, -0.028669517310693903, 0.005897463180501999, 0.007160730615422286, -0.02628925597302477, -0.0016671803130552693, 0.03470660577677746, 0.015996952550629155, 0.010691229882757532, -0.018031477125945893, -0.017393195161895872, -0.01107685891861707, 0.05031792742890182, -0.002672807470689383, -0.014254973177010041, -0.02671477728239145, 0.00558497091072818, 0.003972642822991214, -7.064323705703387e-05, 0.02664829015987955, -0.008623460814862217, 0.03428108446741079, 0.02620947142601049, 0.007739174169211594, -0.03273856832397263, 0.027193490152412906, -0.007087593849336566, 0.0018915764470088486, -0.001574928615662707, -0.02543821335429141, -0.006010492685756173, -0.03622252707121086, -0.013290901518683824, -0.010185923095053943, 0.012453155393130216, -0.020305359067595986, 0.08281714211183161, 0.017526171269564933, -0.03231304701460595, 0.012353423778039737, 0.0063662020508240425, -0.0004263526894363995, 0.005704648662572229, 0.016223010629814877, 0.0028190805371995074, 0.01877614034866021, 0.028164211454312943, -0.015890571291964858, 0.006389472543703208, -0.008590217253606267, -0.024866418512753292, -0.013377334777949295, 0.00369339458013466, 0.01898890100334355, 0.004800415414506722, -0.00361360910179775, 0.014042212522326703, 0.01773893192424827, 0.007765769018216354, 0.0056481341427758, -0.01474698254021125, -0.0012291923189716228, 0.051408327413968544, 0.011834819565833769, -0.008191290793244347, -0.015145909000573169, -0.01902879327685069, -4.716474636531979e-05, -0.041328786508901524, 0.0005900788002288909, -0.008450593365008648, 0.004694035087165052, 0.011655302472406379, 0.0021492164914643642, 0.020970235880650764, 0.02928120442573916, 0.014068807371331463, 0.023230820397798477, -0.0015466712393491634, -0.02601000819582953, 0.010485117940325382, 0.007752471593713974, 0.0030152194112548717, -0.001936455720365696, -0.021422352039022204]\n"
          ]
        }
      ],
      "source": [
        "# Turn the first text chunk into a vector with the embedding\n",
        "\n",
        "query_result = embeddings.embed_query(texts[0].page_content)\n",
        "print(query_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QaOY5bIZM3Xz"
      },
      "outputs": [],
      "source": [
        "# Import and initialize Pinecone client\n",
        "# You will need to create a Pinecone account and create an API key and environment variable, see www.pinecone.io\n",
        "\n",
        "pinecone.init(\n",
        "    api_key=os.getenv('PINECONE_API_KEY'),  \n",
        "    environment=os.getenv('PINECONE_ENV')  \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create an index\n",
        "# NOTE: For free version, you can only create one index. If you want to create a new index, you need to delete the old one first.\n",
        "# \n",
        "\n",
        "pinecone.init(api_key=os.getenv('PINECONE_API_KEY'), environment=os.getenv('PINECONE_ENV'))\n",
        "\n",
        "#pinecone.delete_index(\"langchain-demo-index\")\n",
        "\n",
        "pinecone.create_index(\"langchain-demo-index\", dimension=1536) # 1536 is openai ada embedding dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lZhSUt3FNBzN"
      },
      "outputs": [],
      "source": [
        "# Upload vectors to Pinecone\n",
        "# You need first create an index in Pinecone, see www.pinecone.io - set it to 1536 dimensions\n",
        "\n",
        "index_name = \"langchain-demo-index\"\n",
        "search = Pinecone.from_documents(texts, embeddings, index_name=index_name) # load all text chunks into Pinecone with the associated embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cCXVuXwPNKcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(page_content='understand it better, an autoencoder could help you break it down into smaller, more manageable', metadata={}),\n",
            " Document(page_content='Autoencoders can help you reduce the amount of data you have to work with, which can make it easier', metadata={}),\n",
            " Document(page_content='one of them looks really different from the rest, an autoencoder can help you detect that.', metadata={}),\n",
            " Document(page_content='To use an autoencoder, you first need to give it', metadata={})]\n"
          ]
        }
      ],
      "source": [
        "# Do a simple vector similarity search\n",
        "\n",
        "query = \"about an autoencoder?\"\n",
        "result = search.similarity_search(query)\n",
        "\n",
        "pprint(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agents\n",
        "\n",
        "Agents in LangChain have memory (but, you can also use zeroshot to get the answer, which wouldn't hold memory). Agents can be used to create and execute Python code to find answer. (notice that the agent has 'memory' of previous answers). See more here above memory: https://python.langchain.com/docs/modules/memory/agent_with_memory\n",
        "\n",
        "> NOTE: See Memory Store backed memory options here: https://python.langchain.com/docs/modules/memory/types/vectorstore_retriever_memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "4Ogz8luZNRnJ"
      },
      "outputs": [],
      "source": [
        "# Instantiate Python agent\n",
        "\n",
        "agent_executor = create_python_agent(\n",
        "    llm=OpenAI(temperature=0, max_tokens=2000),\n",
        "    tool=PythonREPLTool(), # Read-Eval-Print Loop (REPL) tool\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to load the csv file into a dataframe and then get the number of rows and columns\n",
            "Action: Python_REPL\n",
            "Action Input: import pandas as pd\n",
            "df = pd.read_csv('https://raw.githubusercontent.com/patelchandan0912/Data-Science-Programming/master/DSP-3-%20SVM%2C%20Logistic%20Regression/RidingMowers.csv')\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now need to get the number of rows and columns\n",
            "Action: Python_REPL\n",
            "Action Input: print(df.shape)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m(24, 3)\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The dataframe has 24 rows and 3 columns.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'The dataframe has 24 rows and 3 columns.'"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Execute the Python agent\n",
        "\n",
        "agent_executor.run(\"Load a csv file found at https://raw.githubusercontent.com/patelchandan0912/Data-Science-Programming/master/DSP-3-%20SVM%2C%20Logistic%20Regression/RidingMowers.csv into a dataframe, and tell me the number of rows and columns in the dataframe\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to look at the dataframe\n",
            "Action: Python_REPL\n",
            "Action Input: print(df)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m    Income  Lot_Size Ownership\n",
            "0     60.0      18.4     Owner\n",
            "1     85.5      16.8     Owner\n",
            "2     64.8      21.6     Owner\n",
            "3     61.5      20.8     Owner\n",
            "4     87.0      23.6     Owner\n",
            "5    110.1      19.2     Owner\n",
            "6    108.0      17.6     Owner\n",
            "7     82.8      22.4     Owner\n",
            "8     69.0      20.0     Owner\n",
            "9     93.0      20.8     Owner\n",
            "10    51.0      22.0     Owner\n",
            "11    81.0      20.0     Owner\n",
            "12    75.0      19.6  Nonowner\n",
            "13    52.8      20.8  Nonowner\n",
            "14    64.8      17.2  Nonowner\n",
            "15    43.2      20.4  Nonowner\n",
            "16    84.0      17.6  Nonowner\n",
            "17    49.2      17.6  Nonowner\n",
            "18    59.4      16.0  Nonowner\n",
            "19    66.0      18.4  Nonowner\n",
            "20    47.4      16.4  Nonowner\n",
            "21    33.0      18.8  Nonowner\n",
            "22    51.0      14.0  Nonowner\n",
            "23    63.0      14.8  Nonowner\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The dataframe contains columns for Income, Lot_Size, and Ownership, with 24 rows of data.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'The dataframe contains columns for Income, Lot_Size, and Ownership, with 24 rows of data.'"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_executor.run(\"Describe the dataframe\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to split the dataframe, set the target, fit the model, and then report the accuracy, precision, and recall\n",
            "Action: Python_REPL\n",
            "Action Input: \n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.tree import DecisionTreeClassifier\n",
            "\n",
            "X = df.drop('Ownership', axis=1)\n",
            "y = df['Ownership']\n",
            "\n",
            "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
            "\n",
            "clf = DecisionTreeClassifier()\n",
            "clf.fit(X_train, y_train)\n",
            "\n",
            "y_pred = clf.predict(X_test)\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now need to report the accuracy, precision, and recall\n",
            "Action: Python_REPL\n",
            "Action Input: \n",
            "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
            "\n",
            "accuracy = accuracy_score(y_test, y_pred)\n",
            "precision = precision_score(y_test, y_pred)\n",
            "recall = recall_score(y_test, y_pred)\n",
            "\n",
            "print(f'Accuracy: {accuracy}')\n",
            "print(f'Precision: {precision}')\n",
            "print(f'Recall: {recall}')\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mValueError(\"pos_label=1 is not a valid label. It should be one of ['Nonowner', 'Owner']\")\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to specify the labels for the metrics\n",
            "Action: Python_REPL\n",
            "Action Input: \n",
            "accuracy = accuracy_score(y_test, y_pred, labels=['Nonowner', 'Owner'])\n",
            "precision = precision_score(y_test, y_pred, labels=['Nonowner', 'Owner'])\n",
            "recall = recall_score(y_test, y_pred, labels=['Nonowner', 'Owner'])\n",
            "\n",
            "print(f'Accuracy: {accuracy}')\n",
            "print(f'Precision: {precision}')\n",
            "print(f'Recall: {recall}')\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mTypeError(\"got an unexpected keyword argument 'labels'\")\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to use the correct syntax for the metrics\n",
            "Action: Python_REPL\n",
            "Action Input: \n",
            "accuracy = accuracy_score(y_test, y_pred, pos_label='Owner')\n",
            "precision = precision_score(y_test, y_pred, pos_label='Owner')\n",
            "recall = recall_score(y_test, y_pred, pos_label='Owner')\n",
            "\n",
            "print(f'Accuracy: {accuracy}')\n",
            "print(f'Precision: {precision}')\n",
            "print(f'Recall: {recall}')\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mTypeError(\"got an unexpected keyword argument 'pos_label'\")\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to use the correct syntax for the metrics\n",
            "Action: Python_REPL\n",
            "Action Input: \n",
            "accuracy = accuracy_score(y_test, y_pred, labels=['Nonowner', 'Owner'])\n",
            "precision = precision_score(y_test, y_pred, labels=['Nonowner', 'Owner'])\n",
            "recall = recall_score(y_test, y_pred, labels=['Nonowner', 'Owner'])\n",
            "\n",
            "print(f'Accuracy: {accuracy}')\n",
            "print(f'Precision: {precision}')\n",
            "print(f'Recall: {recall}')\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mTypeError(\"got an unexpected keyword argument 'labels'\")\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to use the correct syntax for the metrics\n",
            "Action: Python_REPL\n",
            "Action Input: \n",
            "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
            "\n",
            "accuracy = accuracy_score(y_test, y_pred)\n",
            "precision = precision_score(y_test, y_pred, pos_label='Owner')\n",
            "recall = recall_score(y_test, y_pred, pos_label='Owner')\n",
            "\n",
            "print(f'Accuracy: {accuracy}')\n",
            "print(f'Precision: {precision}')\n",
            "print(f'Recall: {recall}')\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAccuracy: 0.4\n",
            "Precision: 0.5\n",
            "Recall: 0.3333333333333333\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The accuracy, precision, and recall of the decision tree model are 0.4, 0.5, and 0.3333333333333333 respectively.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'The accuracy, precision, and recall of the decision tree model are 0.4, 0.5, and 0.3333333333333333 respectively.'"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_executor.run(r\"Coduct a train-test split of the dataframe using 80% for training and 20% for testing. Set 'Ownership' column as the target and then fit a decision tree model to the training data and report the accuracy, precision and recall on the test data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion\n",
        "\n",
        "From the example above, we utilized the REPL agent to access data stored in my GitHub repository and read a CSV file. The REPL agent effectively interpreted the data within the dataframe, offering valuable insights and functionalities. This versatile tool can be applied to various dataframe tasks, including data cleaning, calculations, and generating new insights.\n",
        "\n",
        "In the demonstration, we showcased how the agent described the dataframe's characteristics. Specifically, we instructed the agent to split the dataframe into 80% training data and 20% testing data, then apply a decision tree machine learning model to this data, and finally report the accuracy, precision, and recall of the model.\n",
        "\n",
        "The agent flawlessly executed these instructions by creating the necessary Python script, applying it to the dataframe, and providing the desired output. This highlights the utility of agents like REPL, which have access to powerful resources such as an LLM and a suite of tools including Google Search, Python REPL, math calculators, weather APIs, and more."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyONM96f7/m0jUCD9c87+MQy",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
